{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries, features and settings\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, f1_score, accuracy_score, roc_curve, auc\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import time\n",
    "import io\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, VarianceThreshold, mutual_info_classif, RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "plt.rc(\"font\", size = 14)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C0</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>...</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "      <th>C27</th>\n",
       "      <th>C28</th>\n",
       "      <th>C29</th>\n",
       "      <th>C30</th>\n",
       "      <th>regression target</th>\n",
       "      <th>classification target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>divorced</td>\n",
       "      <td>Holders of other higher courses</td>\n",
       "      <td>second choice</td>\n",
       "      <td>Management</td>\n",
       "      <td>daytime</td>\n",
       "      <td>Higher education - degree</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>single</td>\n",
       "      <td>Over 23 years old</td>\n",
       "      <td>second choice</td>\n",
       "      <td>Veterinary Nursing</td>\n",
       "      <td>daytime</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>single</td>\n",
       "      <td>1st phase - general contingent</td>\n",
       "      <td>seventh choice</td>\n",
       "      <td>Communication Design</td>\n",
       "      <td>daytime</td>\n",
       "      <td>Frequency of higher education</td>\n",
       "      <td>59.50</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.6160</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>married</td>\n",
       "      <td>Over 23 years old</td>\n",
       "      <td>second choice</td>\n",
       "      <td>Social Service</td>\n",
       "      <td>daytime</td>\n",
       "      <td>Basic education 3rd cycle (9th/10th/11th year)...</td>\n",
       "      <td>66.55</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>0.5175</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>single</td>\n",
       "      <td>1st phase - general contingent</td>\n",
       "      <td>fourth choice</td>\n",
       "      <td>Nursing</td>\n",
       "      <td>daytime</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>71.00</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.6865</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>single</td>\n",
       "      <td>1st phase - general contingent</td>\n",
       "      <td>third choice</td>\n",
       "      <td>Communication Design</td>\n",
       "      <td>daytime</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>67.00</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.6385</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>single</td>\n",
       "      <td>1st phase - general contingent</td>\n",
       "      <td>second choice</td>\n",
       "      <td>Basic Education</td>\n",
       "      <td>daytime</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>66.50</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>single</td>\n",
       "      <td>1st phase - general contingent</td>\n",
       "      <td>second choice</td>\n",
       "      <td>Social Service (evening attendance)</td>\n",
       "      <td>evening</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>50.00</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>0.5640</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>single</td>\n",
       "      <td>1st phase - general contingent</td>\n",
       "      <td>fifth choice</td>\n",
       "      <td>Social Service</td>\n",
       "      <td>daytime</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>63.50</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.6020</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>single</td>\n",
       "      <td>3rd phase - general contingent</td>\n",
       "      <td>third choice</td>\n",
       "      <td>Informatics Engineering</td>\n",
       "      <td>daytime</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>68.00</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.6135</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3539 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            C0                               C1              C2  \\\n",
       "0     divorced  Holders of other higher courses   second choice   \n",
       "1       single                Over 23 years old   second choice   \n",
       "2       single   1st phase - general contingent  seventh choice   \n",
       "3      married                Over 23 years old   second choice   \n",
       "4       single   1st phase - general contingent   fourth choice   \n",
       "...        ...                              ...             ...   \n",
       "3534    single   1st phase - general contingent    third choice   \n",
       "3535    single   1st phase - general contingent   second choice   \n",
       "3536    single   1st phase - general contingent   second choice   \n",
       "3537    single   1st phase - general contingent    fifth choice   \n",
       "3538    single   3rd phase - general contingent    third choice   \n",
       "\n",
       "                                       C3       C4  \\\n",
       "0                              Management  daytime   \n",
       "1                      Veterinary Nursing  daytime   \n",
       "2                    Communication Design  daytime   \n",
       "3                          Social Service  daytime   \n",
       "4                                 Nursing  daytime   \n",
       "...                                   ...      ...   \n",
       "3534                 Communication Design  daytime   \n",
       "3535                      Basic Education  daytime   \n",
       "3536  Social Service (evening attendance)  evening   \n",
       "3537                       Social Service  daytime   \n",
       "3538              Informatics Engineering  daytime   \n",
       "\n",
       "                                                     C5     C6          C7  \\\n",
       "0                             Higher education - degree  65.00  Portuguese   \n",
       "1                                   Secondary education  65.00  Portuguese   \n",
       "2                         Frequency of higher education  59.50  Portuguese   \n",
       "3     Basic education 3rd cycle (9th/10th/11th year)...  66.55  Portuguese   \n",
       "4                                   Secondary education  71.00  Portuguese   \n",
       "...                                                 ...    ...         ...   \n",
       "3534                                Secondary education  67.00  Portuguese   \n",
       "3535                                Secondary education  66.50  Portuguese   \n",
       "3536                                Secondary education  50.00  Portuguese   \n",
       "3537                                Secondary education  63.50  Portuguese   \n",
       "3538                                Secondary education  68.00  Portuguese   \n",
       "\n",
       "       C8  C9  ...  C23 C24  C25        C26  C27   C28  C29   C30  \\\n",
       "0      no  no  ...  5.0   5  0.0   0.000000    0  11.1  0.6  2.02   \n",
       "1      no  no  ...  6.0  14  2.0  11.333333    0  11.1  0.6  2.02   \n",
       "2     yes  no  ...  6.0   8  6.0  13.625000    0  10.8  1.4  1.74   \n",
       "3      no  no  ...  6.0   0  0.0   0.000000    0  15.5  2.8 -4.06   \n",
       "4     yes  no  ...  7.0   7  6.0  13.900000    0   7.6  2.6  0.32   \n",
       "...   ...  ..  ...  ...  ..  ...        ...  ...   ...  ...   ...   \n",
       "3534  yes  no  ...  6.0  11  4.0  11.333333    0  13.9  NaN  0.79   \n",
       "3535  yes  no  ...  8.0   8  8.0  12.625000    0  15.5  2.8 -4.06   \n",
       "3536   no  no  ...  6.0   6  NaN  12.500000    0  12.7  3.7 -1.70   \n",
       "3537  yes  no  ...  6.0   7  6.0  13.428571    0  11.1  0.6  2.02   \n",
       "3538  yes  no  ...  5.0   9  3.0  13.250000    0  13.9 -0.3  0.79   \n",
       "\n",
       "      regression target  classification target  \n",
       "0                0.6500                failure  \n",
       "1                0.5500                success  \n",
       "2                0.6160                success  \n",
       "3                0.5175                failure  \n",
       "4                0.6865                success  \n",
       "...                 ...                    ...  \n",
       "3534             0.6385                failure  \n",
       "3535             0.6565                success  \n",
       "3536             0.5640                success  \n",
       "3537             0.6020                success  \n",
       "3538             0.6135                failure  \n",
       "\n",
       "[3539 rows x 33 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the train & test csvs as dataframes\n",
    "\n",
    "df_train = pd.read_csv('../Data/train.csv')\n",
    "df_test = pd.read_csv('../Data/test.csv')\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 - [Q7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numerical and categorical features\n",
    "num_features = df_train.select_dtypes(include=['float64', 'int64'])\n",
    "cat_features = df_train.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out which features are binary\n",
    "bin_features = cat_features.nunique()\n",
    "bin_features = bin_features[bin_features == 2]\n",
    "bin_features = bin_features.drop('classification target')\n",
    "bin_features = cat_features[bin_features.index]\n",
    "\n",
    "# Store ordinal features\n",
    "ord_features = cat_features[['C2', 'C5']]\n",
    "\n",
    "# Store nominal features\n",
    "nom_features = cat_features[['C0', 'C1', 'C3', 'C7']]\n",
    "\n",
    "# Store continuous features\n",
    "cont_features = num_features[['C6','C20', 'C26', 'C28', 'C29', 'C30', 'regression target']]\n",
    "\n",
    "# Store discrete features\n",
    "disc_features = num_features[['C14', 'C16', 'C17', 'C18', 'C19', 'C21', 'C22', 'C23', 'C24', 'C25', 'C27']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Remove non empty features from the binary, ordinal, nominal, continuous and discrete features\n",
    "bin_missing = bin_features.columns[bin_features.isnull().any()]\n",
    "ord_missing = ord_features.columns[ord_features.isnull().any()]\n",
    "nom_missing = nom_features.columns[nom_features.isnull().any()]\n",
    "cont_missing = cont_features.columns[cont_features.isnull().any()]\n",
    "disc_missing = disc_features.columns[disc_features.isnull().any()]\n",
    "\n",
    "# Make an imputed df\n",
    "df_imputed = df_train.copy()\n",
    "\n",
    "# Impute the missing values in binary features\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer = imputer.fit(bin_features[bin_missing])\n",
    "df_imputed[bin_missing] = imputer.transform(bin_features[bin_missing])\n",
    "\n",
    "# Impute the missing values in the ordinal features\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer = imputer.fit(ord_features[ord_missing])\n",
    "df_imputed[ord_missing] = imputer.transform(ord_features[ord_missing])\n",
    "\n",
    "# Impute the missing values in the nominal features\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer = imputer.fit(nom_features[nom_missing])\n",
    "df_imputed[nom_missing] = imputer.transform(nom_features[nom_missing])\n",
    "\n",
    "# Impute the missing values in the continuous features\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer = imputer.fit(cont_features[cont_missing])\n",
    "df_imputed[cont_missing] = imputer.transform(cont_features[cont_missing])\n",
    "\n",
    "# Impute the missing values in the discrete features\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer = imputer.fit(disc_features[disc_missing])\n",
    "df_imputed[disc_missing] = imputer.transform(disc_features[disc_missing])\n",
    "\n",
    "\n",
    "# Check if there are any missing values left\n",
    "print(df_imputed.isnull().sum()[df_imputed.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "0    65.00\n",
      "1    65.00\n",
      "2    59.50\n",
      "3    66.55\n",
      "4    71.00\n",
      "5    70.00\n",
      "6    57.50\n",
      "7    65.50\n",
      "8    70.00\n",
      "9    80.00\n",
      "Name: C6, dtype: float64\n",
      "After:\n",
      "0   -0.200135\n",
      "1   -0.200135\n",
      "2   -1.031074\n",
      "3    0.034039\n",
      "4    0.706344\n",
      "5    0.555264\n",
      "6   -1.333234\n",
      "7   -0.124595\n",
      "8    0.555264\n",
      "9    2.066063\n",
      "Name: C6, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select the numerical features\n",
    "imputed_nf = df_imputed.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Report first 10 samples of first numerical feature\n",
    "print(\"Before:\")\n",
    "print(imputed_nf.iloc[:, 0].head(10))\n",
    "\n",
    "# Initialize scalers\n",
    "robust = RobustScaler()\n",
    "standard = StandardScaler()\n",
    "\n",
    "# Apply the RobustScaler to the discrete features\n",
    "df_imputed[disc_features.columns] = robust.fit_transform(imputed_nf[disc_features.columns])\n",
    "\n",
    "# Apply the StandardScaler to the continuous features\n",
    "df_imputed[cont_features.columns] = standard.fit_transform(imputed_nf[cont_features.columns])\n",
    "\n",
    "# Report first 10 samples of first numerical feature after scaling\n",
    "print(\"After:\")\n",
    "print(df_imputed[imputed_nf.columns].iloc[:, 0].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    divorced\n",
      "1      single\n",
      "2      single\n",
      "3     married\n",
      "4      single\n",
      "5      single\n",
      "6      single\n",
      "7      single\n",
      "8      single\n",
      "9      single\n",
      "Name: C0, dtype: object\n",
      "   C0_divorced  C0_facto union  C0_legally separated  C0_married  C0_single  \\\n",
      "0          1.0             0.0                   0.0         0.0        0.0   \n",
      "1          0.0             0.0                   0.0         0.0        1.0   \n",
      "2          0.0             0.0                   0.0         0.0        1.0   \n",
      "3          0.0             0.0                   0.0         1.0        0.0   \n",
      "4          0.0             0.0                   0.0         0.0        1.0   \n",
      "5          0.0             0.0                   0.0         0.0        1.0   \n",
      "6          0.0             0.0                   0.0         0.0        1.0   \n",
      "7          0.0             0.0                   0.0         0.0        1.0   \n",
      "8          0.0             0.0                   0.0         0.0        1.0   \n",
      "9          0.0             0.0                   0.0         0.0        1.0   \n",
      "\n",
      "   C0_widower  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         0.0  \n",
      "5         0.0  \n",
      "6         0.0  \n",
      "7         0.0  \n",
      "8         0.0  \n",
      "9         0.0  \n"
     ]
    }
   ],
   "source": [
    "# Select the numerical features\n",
    "imputed_df = df_imputed.select_dtypes(include=['object'])\n",
    "# Report first 10 samples of first numerical feature\n",
    "print(imputed_df.iloc[:, 0].head(10))\n",
    "\n",
    "# Initialize the encoders\n",
    "onehot = OneHotEncoder(sparse_output=False)\n",
    "ordinal = OrdinalEncoder(\n",
    "categories = \n",
    "[\n",
    "    ['first choice', 'second choice', 'third choice', 'fourth choice', 'fifth choice', 'sixth choice', 'seventh choice', 'last choice'],\n",
    "    ['Basic education 2nd cycle (6th/7th/8th year) or equiv.', 'Basic education 3rd cycle (9th/10th/11th year) or equiv.', 'Secondary education', '10th year of schooling - not completed', '10th year of schooling', '11th year of schooling - not completed', 'Other - 11th year of schooling', '12th year of schooling - not completed', 'Technological specialization course', 'Professional higher technical course', 'Frequency of higher education', 'Higher education - degree', 'Higher education - degree (1st cycle)', \"Higher education - bachelor's degree\", 'Higher education - master (2nd cycle)', \"Higher education - master's\", 'Higher education - doctorate']\n",
    "]\n",
    ")\n",
    "# Apply the OneHotEncoder to the nominal features\n",
    "onehot_encoded = onehot.fit_transform(imputed_df[nom_features.columns])\n",
    "onehot_encoded_nom = pd.DataFrame(onehot_encoded, columns=onehot.get_feature_names_out(nom_features.columns))\n",
    "\n",
    "# Apply the OneHotEncoder to the binary features\n",
    "onehot_encoded = onehot.fit_transform(imputed_df[bin_features.columns])\n",
    "onehot_encoded_bin = pd.DataFrame(onehot_encoded, columns=onehot.get_feature_names_out(bin_features.columns))\n",
    "\n",
    "# Apply the OrdinalEncoder to the ordinal features\n",
    "ordinal_encoded = ordinal.fit_transform(imputed_df[ord_features.columns])\n",
    "ordinal_encoded_df = pd.DataFrame(ordinal_encoded, columns=ord_features.columns)\n",
    "df_imputed[ord_features.columns] = ordinal_encoded_df\n",
    "\n",
    "# Apply label encoder to the classification target\n",
    "label = LabelEncoder()\n",
    "label_encoded = label.fit_transform(df_imputed['classification target'])\n",
    "df_imputed['classification target'] = label_encoded\n",
    "\n",
    "# Merge the standardised results\n",
    "df_merged = pd.concat([df_imputed, onehot_encoded_nom, onehot_encoded_bin], axis=1)\n",
    "\n",
    "# Drop the original columns\n",
    "df_merged = df_merged.drop(nom_features.columns, axis=1)\n",
    "df_merged = df_merged.drop(bin_features.columns, axis=1)\n",
    "\n",
    "# Report the first 10 samples of the first categorical feature after encoding (all columns starting with C0)\n",
    "print(df_merged.filter(regex='^C0_').head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C2</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C14</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>...</th>\n",
       "      <th>C10_no</th>\n",
       "      <th>C10_yes</th>\n",
       "      <th>C11_no</th>\n",
       "      <th>C11_yes</th>\n",
       "      <th>C12_female</th>\n",
       "      <th>C12_male</th>\n",
       "      <th>C13_no</th>\n",
       "      <th>C13_yes</th>\n",
       "      <th>C15_no</th>\n",
       "      <th>C15_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.200135</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>-2.244836e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.200135</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>2.201216e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.031074</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>7.483267e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034039</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>-2.244836e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.706344</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.753123e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.102025</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.301826e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.026485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.835404e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.466332</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>7.483267e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.426755</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6.074720e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.253105</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.173182e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3539 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       C2    C5        C6       C14  C16  C17   C18       C19           C20  \\\n",
       "0     1.0  11.0 -0.200135  2.500000  0.0 -0.5 -0.75 -1.666667 -2.244836e+00   \n",
       "1     1.0   2.0 -0.200135  0.833333  0.0  0.0  1.25 -0.666667  2.201216e-01   \n",
       "2     6.0  10.0 -1.031074  0.333333  0.0  0.0 -0.50  0.333333  7.483267e-01   \n",
       "3     1.0   1.0  0.034039  3.666667  0.0  0.0 -2.00 -1.666667 -2.244836e+00   \n",
       "4     3.0   2.0  0.706344  0.333333  0.0  0.5 -0.25  0.333333  3.753123e-16   \n",
       "...   ...   ...       ...       ...  ...  ...   ...       ...           ...   \n",
       "3534  2.0   2.0  0.102025 -0.333333  1.0  0.0  0.00  0.333333  2.301826e-01   \n",
       "3535  1.0   2.0  0.026485  0.000000  0.0  0.0  0.25  0.000000  7.835404e-01   \n",
       "3536  1.0   2.0 -2.466332  0.500000  0.0  0.0 -0.50  0.333333  7.483267e-01   \n",
       "3537  4.0   2.0 -0.426755 -0.166667  0.0  0.0 -0.50  0.333333  6.074720e-01   \n",
       "3538  2.0   2.0  0.253105 -0.333333  0.0 -0.5 -0.25  0.000000  4.173182e-01   \n",
       "\n",
       "      C21  ...  C10_no  C10_yes  C11_no  C11_yes  C12_female  C12_male  \\\n",
       "0     0.0  ...     1.0      0.0     0.0      1.0         1.0       0.0   \n",
       "1     0.0  ...     1.0      0.0     0.0      1.0         1.0       0.0   \n",
       "2     0.0  ...     1.0      0.0     0.0      1.0         0.0       1.0   \n",
       "3     0.0  ...     1.0      0.0     0.0      1.0         0.0       1.0   \n",
       "4     0.0  ...     1.0      0.0     0.0      1.0         1.0       0.0   \n",
       "...   ...  ...     ...      ...     ...      ...         ...       ...   \n",
       "3534  1.0  ...     1.0      0.0     1.0      0.0         1.0       0.0   \n",
       "3535  0.0  ...     1.0      0.0     0.0      1.0         1.0       0.0   \n",
       "3536  0.0  ...     1.0      0.0     0.0      1.0         1.0       0.0   \n",
       "3537  0.0  ...     1.0      0.0     0.0      1.0         1.0       0.0   \n",
       "3538  0.0  ...     1.0      0.0     0.0      1.0         0.0       1.0   \n",
       "\n",
       "      C13_no  C13_yes  C15_no  C15_yes  \n",
       "0        1.0      0.0     1.0      0.0  \n",
       "1        0.0      1.0     1.0      0.0  \n",
       "2        1.0      0.0     1.0      0.0  \n",
       "3        1.0      0.0     1.0      0.0  \n",
       "4        0.0      1.0     1.0      0.0  \n",
       "...      ...      ...     ...      ...  \n",
       "3534     1.0      0.0     1.0      0.0  \n",
       "3535     1.0      0.0     1.0      0.0  \n",
       "3536     0.0      1.0     1.0      0.0  \n",
       "3537     0.0      1.0     1.0      0.0  \n",
       "3538     1.0      0.0     1.0      0.0  \n",
       "\n",
       "[3539 rows x 97 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Q10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C20', 'C3_Veterinary Nursing', 'C3_Management', 'C13_yes', 'C25', 'C10_no', 'C28', 'C3_Advertising and Marketing Management', 'C26', 'C2', 'C18', 'C1_2nd phase - general contingent', 'C7_Cuban', 'C27', 'C11_no', 'C30', 'C1_1st phase - general contingent', 'C1_Change of course', 'C17', 'C14', 'C19', 'C12_female', 'C3_Animation and Multimedia Design', 'C1_Ordinance No. 854-B/99', 'C23', 'C6', 'C3_Tourism', 'C1_Over 23 years old', 'C5', 'C24', 'C11_yes', 'C1_Technological specialization diploma holders', 'C10_yes', 'C22', 'C3_Agronomy', 'C16', 'C29']\n",
      "SelectKBest reg removed features:['C7_Italian', 'C13_no', 'classification target', 'C10_no', 'C1_Ordinance No. 533-A/99, item b3 (Other Institution)', 'C1_1st phase - special contingent (Azores Island)', 'C3_Social Service', 'C7_German', 'C3_Oral Hygiene', 'C9_no', 'C7_Lithuanian', 'C3_Communication Design', 'C27', 'C7_Spanish', 'C1_Ordinance No. 533-A/99, item b2) (Different Plan)', 'C1_Transfer', 'C30', 'C1_1st phase - general contingent', 'C1_1st phase - special contingent (Madeira Island)', 'C0_legally separated', 'C17', 'C7_Guinean', 'C21', 'C15_no', 'C7_Russian', 'C3_Nursing', 'C23', 'C3_Equinculture', 'C24', 'C0_widower', 'C22', 'C3_Informatics Engineering', 'regression target', 'C1_International student (bachelor)', 'C1_3rd phase - general contingent', 'C16', 'C29', 'C0_married', 'C12_male', 'C7_Moldova (Republic of)', 'C4_evening', 'C7_Turkish', 'C1_Short cycle diploma holders', 'C7_Brazilian', 'C13_yes', 'C28', 'C7_Mozambican', 'C7_Ukrainian', 'C3_Biofuel Production Technologies', 'C3_Management (evening attendance)', 'C7_Dutch', 'C7_Colombian', 'C1_Ordinance No. 612/93', 'C0_facto union', 'C1_Change of institution/course', 'C3_Social Service (evening attendance)', 'C3_Journalism and Communication', 'C15_yes', 'C14', 'C4_daytime', 'C3_Basic Education', 'C19', 'C12_female', 'C7_Santomean', 'C1_Change of institution/course (International)', 'C1_Holders of other higher courses', 'C0_divorced', 'C1_Over 23 years old', 'C8_yes', 'C7_Angolan', 'C7_Portuguese', 'C7_Cape Verdean', 'C0_single', 'C10_yes', 'C7_Mexican', 'C8_no', 'C9_yes']\n",
      "SelectKBest class removed features:['C7_Italian', 'C3_Management', 'C13_no', 'classification target', 'C1_Ordinance No. 533-A/99, item b3 (Other Institution)', 'C3_Advertising and Marketing Management', 'C1_1st phase - special contingent (Azores Island)', 'C3_Social Service', 'C7_German', 'C3_Oral Hygiene', 'C9_no', 'C2', 'C7_Lithuanian', 'C3_Communication Design', 'C1_2nd phase - general contingent', 'C27', 'C7_Spanish', 'C1_Ordinance No. 533-A/99, item b2) (Different Plan)', 'C1_Transfer', 'C30', 'C1_Change of course', 'C1_1st phase - special contingent (Madeira Island)', 'C0_legally separated', 'C7_Guinean', 'C21', 'C15_no', 'C7_Russian', 'C3_Nursing', 'C1_Ordinance No. 854-B/99', 'C3_Tourism', 'C3_Equinculture', 'C1_Technological specialization diploma holders', 'C0_widower', 'C22', 'C3_Informatics Engineering', 'regression target', 'C1_International student (bachelor)', 'C1_3rd phase - general contingent', 'C3_Agronomy', 'C16', 'C29', 'C0_married', 'C3_Veterinary Nursing', 'C12_male', 'C7_Moldova (Republic of)', 'C4_evening', 'C7_Turkish', 'C1_Short cycle diploma holders', 'C7_Brazilian', 'C28', 'C7_Mozambican', 'C7_Ukrainian', 'C3_Biofuel Production Technologies', 'C3_Management (evening attendance)', 'C7_Dutch', 'C7_Colombian', 'C1_Ordinance No. 612/93', 'C0_facto union', 'C1_Change of institution/course', 'C3_Social Service (evening attendance)', 'C3_Journalism and Communication', 'C15_yes', 'C4_daytime', 'C3_Basic Education', 'C3_Animation and Multimedia Design', 'C7_Santomean', 'C1_Change of institution/course (International)', 'C1_Holders of other higher courses', 'C0_divorced', 'C8_yes', 'C7_Angolan', 'C7_Portuguese', 'C7_Cape Verdean', 'C0_single', 'C7_Mexican', 'C8_no', 'C9_yes']\n",
      "VarianceThreshold removed features:['C7_Italian', 'C3_Management', 'C13_no', 'classification target', 'C10_no', 'C1_Ordinance No. 533-A/99, item b3 (Other Institution)', 'C3_Advertising and Marketing Management', 'C1_1st phase - special contingent (Azores Island)', 'C3_Social Service', 'C7_German', 'C3_Oral Hygiene', 'C9_no', 'C7_Lithuanian', 'C3_Communication Design', 'C1_2nd phase - general contingent', 'C7_Spanish', 'C1_Ordinance No. 533-A/99, item b2) (Different Plan)', 'C1_Transfer', 'C1_1st phase - general contingent', 'C1_Change of course', 'C1_1st phase - special contingent (Madeira Island)', 'C0_legally separated', 'C7_Guinean', 'C21', 'C15_no', 'C7_Russian', 'C3_Nursing', 'C1_Ordinance No. 854-B/99', 'C3_Tourism', 'C3_Equinculture', 'C1_Technological specialization diploma holders', 'C0_widower', 'C3_Informatics Engineering', 'regression target', 'C1_International student (bachelor)', 'C1_3rd phase - general contingent', 'C3_Agronomy', 'C0_married', 'C3_Veterinary Nursing', 'C12_male', 'C7_Moldova (Republic of)', 'C4_evening', 'C7_Turkish', 'C1_Short cycle diploma holders', 'C7_Brazilian', 'C13_yes', 'C7_Mozambican', 'C7_Ukrainian', 'C3_Biofuel Production Technologies', 'C3_Management (evening attendance)', 'C7_Dutch', 'C7_Colombian', 'C1_Ordinance No. 612/93', 'C7_Cuban', 'C0_facto union', 'C11_no', 'C1_Change of institution/course', 'C3_Social Service (evening attendance)', 'C3_Journalism and Communication', 'C15_yes', 'C4_daytime', 'C3_Basic Education', 'C12_female', 'C3_Animation and Multimedia Design', 'C7_Santomean', 'C1_Change of institution/course (International)', 'C1_Holders of other higher courses', 'C0_divorced', 'C1_Over 23 years old', 'C8_yes', 'C7_Angolan', 'C7_Portuguese', 'C7_Cape Verdean', 'C0_single', 'C10_yes', 'C11_yes', 'C7_Mexican', 'C8_no', 'C9_yes']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C20</th>\n",
       "      <th>C3_Veterinary Nursing</th>\n",
       "      <th>C3_Management</th>\n",
       "      <th>C13_yes</th>\n",
       "      <th>C25</th>\n",
       "      <th>C10_no</th>\n",
       "      <th>C28</th>\n",
       "      <th>C3_Advertising and Marketing Management</th>\n",
       "      <th>C26</th>\n",
       "      <th>C2</th>\n",
       "      <th>...</th>\n",
       "      <th>C24</th>\n",
       "      <th>C11_yes</th>\n",
       "      <th>C1_Technological specialization diploma holders</th>\n",
       "      <th>C10_yes</th>\n",
       "      <th>C22</th>\n",
       "      <th>C3_Agronomy</th>\n",
       "      <th>C16</th>\n",
       "      <th>C29</th>\n",
       "      <th>regression target</th>\n",
       "      <th>classification target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.244836e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.173556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.962344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.707388e-01</td>\n",
       "      <td>0.217354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.201216e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.173556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.707388e-01</td>\n",
       "      <td>-1.163519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.483267e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.285968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.651839</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.221149e-01</td>\n",
       "      <td>-0.252143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.244836e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.475143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.962344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.159609e+00</td>\n",
       "      <td>-1.612303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.753123e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.485022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704602</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.011395e+00</td>\n",
       "      <td>0.721373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>2.301826e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212145</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.645499e-16</td>\n",
       "      <td>0.058553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>7.835404e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.475143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459973</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.159609e+00</td>\n",
       "      <td>0.307111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>7.483267e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.425971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.826569e+00</td>\n",
       "      <td>-0.970197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>6.074720e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.173556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614151</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.707388e-01</td>\n",
       "      <td>-0.445465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>4.173182e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.579889</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.137699e+00</td>\n",
       "      <td>-0.286665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3539 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               C20  C3_Veterinary Nursing  C3_Management  C13_yes   C25  \\\n",
       "0    -2.244836e+00                    0.0            1.0      0.0 -1.25   \n",
       "1     2.201216e-01                    1.0            0.0      1.0 -0.75   \n",
       "2     7.483267e-01                    0.0            0.0      0.0  0.25   \n",
       "3    -2.244836e+00                    0.0            0.0      0.0 -1.25   \n",
       "4     3.753123e-16                    0.0            0.0      1.0  0.25   \n",
       "...            ...                    ...            ...      ...   ...   \n",
       "3534  2.301826e-01                    0.0            0.0      0.0 -0.25   \n",
       "3535  7.835404e-01                    0.0            0.0      0.0  0.75   \n",
       "3536  7.483267e-01                    0.0            0.0      1.0  0.00   \n",
       "3537  6.074720e-01                    0.0            0.0      1.0  0.25   \n",
       "3538  4.173182e-01                    0.0            0.0      0.0 -0.50   \n",
       "\n",
       "      C10_no       C28  C3_Advertising and Marketing Management       C26  \\\n",
       "0        1.0 -0.173556                                      0.0 -1.962344   \n",
       "1        1.0 -0.173556                                      0.0  0.212145   \n",
       "2        1.0 -0.285968                                      0.0  0.651839   \n",
       "3        1.0  1.475143                                      0.0 -1.962344   \n",
       "4        1.0 -1.485022                                      0.0  0.704602   \n",
       "...      ...       ...                                      ...       ...   \n",
       "3534     1.0  0.875616                                      0.0  0.212145   \n",
       "3535     1.0  1.475143                                      0.0  0.459973   \n",
       "3536     1.0  0.425971                                      0.0  0.435989   \n",
       "3537     1.0 -0.173556                                      0.0  0.614151   \n",
       "3538     1.0  0.875616                                      0.0  0.579889   \n",
       "\n",
       "       C2  ...   C24  C11_yes  \\\n",
       "0     1.0  ... -0.75      1.0   \n",
       "1     1.0  ...  1.50      1.0   \n",
       "2     6.0  ...  0.00      1.0   \n",
       "3     1.0  ... -2.00      1.0   \n",
       "4     3.0  ... -0.25      1.0   \n",
       "...   ...  ...   ...      ...   \n",
       "3534  2.0  ...  0.75      0.0   \n",
       "3535  1.0  ...  0.00      1.0   \n",
       "3536  1.0  ... -0.50      1.0   \n",
       "3537  4.0  ... -0.25      1.0   \n",
       "3538  2.0  ...  0.25      1.0   \n",
       "\n",
       "      C1_Technological specialization diploma holders  C10_yes  C22  \\\n",
       "0                                                 0.0      0.0  0.0   \n",
       "1                                                 0.0      0.0  0.0   \n",
       "2                                                 0.0      0.0  0.0   \n",
       "3                                                 0.0      0.0  0.0   \n",
       "4                                                 0.0      0.0  0.0   \n",
       "...                                               ...      ...  ...   \n",
       "3534                                              0.0      0.0  0.0   \n",
       "3535                                              0.0      0.0  4.0   \n",
       "3536                                              0.0      0.0  0.0   \n",
       "3537                                              0.0      0.0  0.0   \n",
       "3538                                              0.0      0.0  0.0   \n",
       "\n",
       "      C3_Agronomy  C16           C29  regression target  classification target  \n",
       "0             0.0  0.0 -4.707388e-01           0.217354                      0  \n",
       "1             0.0  0.0 -4.707388e-01          -1.163519                      1  \n",
       "2             0.0  0.0  1.221149e-01          -0.252143                      1  \n",
       "3             0.0  0.0  1.159609e+00          -1.612303                      0  \n",
       "4             0.0  0.0  1.011395e+00           0.721373                      1  \n",
       "...           ...  ...           ...                ...                    ...  \n",
       "3534          0.0  1.0 -1.645499e-16           0.058553                      0  \n",
       "3535          0.0  0.0  1.159609e+00           0.307111                      1  \n",
       "3536          0.0  0.0  1.826569e+00          -0.970197                      1  \n",
       "3537          0.0  0.0 -4.707388e-01          -0.445465                      1  \n",
       "3538          0.0  0.0 -1.137699e+00          -0.286665                      0  \n",
       "\n",
       "[3539 rows x 39 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "no_target = df_merged.drop(columns=['regression target', 'classification target'])\n",
    "reg = df_merged['regression target']\n",
    "\n",
    "# Initialize the SelectKBest method with a scoring function suitable for regression\n",
    "selector = SelectKBest(score_func=f_regression, k=20)\n",
    "\n",
    "# fit and get features\n",
    "selector.fit_transform(no_target, reg)\n",
    "selected_features_reg = no_target.columns[selector.get_support()]\n",
    "\n",
    "# Now for the classification targets\n",
    "class_t = df_merged['classification target']\n",
    "\n",
    "# Initialize the SelectKBest method with a scoring function suitable for classification\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=20)\n",
    "\n",
    "# Fit the selector, transform data, get features\n",
    "selector.fit_transform(no_target, class_t)\n",
    "selected_class_feats = no_target.columns[selector.get_support()]\n",
    "\n",
    "\n",
    "# now varthreshold\n",
    "vthresh = VarianceThreshold(threshold=0.5)\n",
    "\n",
    "# Fit adn select features\n",
    "vthresh.fit_transform(no_target)\n",
    "selected_var_feats = no_target.columns[vthresh.get_support()]\n",
    "\n",
    "all_selected_feats = []\n",
    "all_selected_feats.extend(selected_features_reg)\n",
    "all_selected_feats.extend(selected_class_feats)\n",
    "all_selected_feats.extend(selected_var_feats)\n",
    "\n",
    "# Remove duplicates\n",
    "all_selected_feats = list(set(all_selected_feats))\n",
    "print(all_selected_feats)\n",
    "\n",
    "df_selected = df_merged[all_selected_feats + ['regression target', 'classification target']]\n",
    "\n",
    "reg_removed_feats = list(set(df_merged.columns) - set(selected_features_reg))\n",
    "class_removed_feats = list(set(df_merged.columns) - set(selected_class_feats))\n",
    "var_removed_feats = list(set(df_merged.columns) - set(selected_var_feats))\n",
    "\n",
    "print(\"SelectKBest reg removed features:\" + str(reg_removed_feats))\n",
    "print(\"SelectKBest class removed features:\" + str(class_removed_feats))\n",
    "print(\"VarianceThreshold removed features:\" + str(var_removed_feats))\n",
    "\n",
    "df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df_selected into train and test\n",
    "picked_features = ['C6', 'C4_daytime', 'C9_no', 'C12_male', 'C28', 'C29']\n",
    "x = df_merged[picked_features]\n",
    "y = df_merged['regression target']\n",
    "trainX, testX, trainY, testY = train_test_split(x, y, test_size=0.2, random_state=4211)\n",
    "\n",
    "# Select 6 individual features\n",
    "f1 = trainX[picked_features[0]]\n",
    "f2 = trainX[picked_features[1]]\n",
    "f3 = trainX[picked_features[2]]\n",
    "f4 = trainX[picked_features[3]]\n",
    "f5 = trainX[picked_features[4]]\n",
    "f6 = trainX[picked_features[5]]\n",
    "\n",
    "# Select the test data features\n",
    "f1_test = testX[picked_features[0]]\n",
    "f2_test = testX[picked_features[1]]\n",
    "f3_test = testX[picked_features[2]]\n",
    "f4_test = testX[picked_features[3]]\n",
    "f5_test = testX[picked_features[4]]\n",
    "f6_test = testX[picked_features[5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a linear regression model for f1\n",
    "f1model = linear_model.LinearRegression()\n",
    "f1reg = f1model.fit(f1.to_numpy().reshape(-1, 1), trainY)\n",
    "\n",
    "# create a linear regression model for f2\n",
    "f2model = linear_model.LinearRegression()\n",
    "f2reg = f2model.fit(f2.to_numpy().reshape(-1, 1), trainY)\n",
    "\n",
    "# create a linear regression model for f3\n",
    "f3model = linear_model.LinearRegression()\n",
    "f3reg = f3model.fit(f3.to_numpy().reshape(-1, 1), trainY)\n",
    "\n",
    "# create a linear regression model for f4\n",
    "f4model = linear_model.LinearRegression()\n",
    "f4reg = f4model.fit(f4.to_numpy().reshape(-1, 1), trainY)\n",
    "\n",
    "# create a linear regression model for f5\n",
    "f5model = linear_model.LinearRegression()\n",
    "f5reg = f5model.fit(f5.to_numpy().reshape(-1, 1), trainY)\n",
    "\n",
    "# create a linear regression model for f6\n",
    "f6model = linear_model.LinearRegression()\n",
    "f6reg = f6model.fit(f6.to_numpy().reshape(-1, 1), trainY)\n",
    "\n",
    "# create a linear regression model for all features and get time for Q16\n",
    "start = time.time()\n",
    "allmodel = linear_model.LinearRegression()\n",
    "allreg = allmodel.fit(trainX, trainY)\n",
    "end = time.time()\n",
    "linear_reg_time = end - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score for f1: 0.3457983455467899\n",
      "R^2 score for f2: -0.0003744371420333348\n",
      "R^2 score for f3: -0.00038420655713355956\n",
      "R^2 score for f4: 1.7846745361538296e-05\n",
      "R^2 score for f5: 0.0025504461422434233\n",
      "R^2 score for f6: 0.0006419687473383506\n",
      "R^2 score for all features: 0.34860539017166103\n"
     ]
    }
   ],
   "source": [
    "# get the predictions\n",
    "f1pred = f1reg.predict(f1_test.to_numpy().reshape(-1, 1))\n",
    "f2pred = f2reg.predict(f2_test.to_numpy().reshape(-1, 1))\n",
    "f3pred = f3reg.predict(f3_test.to_numpy().reshape(-1, 1))\n",
    "f4pred = f4reg.predict(f4_test.to_numpy().reshape(-1, 1))\n",
    "f5pred = f5reg.predict(f5_test.to_numpy().reshape(-1, 1))\n",
    "f6pred = f6reg.predict(f6_test.to_numpy().reshape(-1, 1))\n",
    "allpred = allreg.predict(testX)\n",
    "\n",
    "# get r^2 scores\n",
    "f1r2 = r2_score(testY, f1pred)\n",
    "f2r2 = r2_score(testY, f2pred)\n",
    "f3r2 = r2_score(testY, f3pred)\n",
    "f4r2 = r2_score(testY, f4pred)\n",
    "f5r2 = r2_score(testY, f5pred)\n",
    "f6r2 = r2_score(testY, f6pred)\n",
    "allr2 = r2_score(testY, allpred)\n",
    "\n",
    "# print r^2 scores\n",
    "print(\"R^2 score for f1: \" + str(f1r2))\n",
    "print(\"R^2 score for f2: \" + str(f2r2))\n",
    "print(\"R^2 score for f3: \" + str(f3r2))\n",
    "print(\"R^2 score for f4: \" + str(f4r2))\n",
    "print(\"R^2 score for f5: \" + str(f5r2))\n",
    "print(\"R^2 score for f6: \" + str(f6r2))\n",
    "print(\"R^2 score for all features: \" + str(allr2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for f1: 0.6068057192641646\n",
      "Mean squared error for f2: 0.9278987995999811\n",
      "Mean squared error for f3: 0.9279078612355126\n",
      "Mean squared error for f4: 0.9275349360957756\n",
      "Mean squared error for f5: 0.9251858197519514\n",
      "Mean squared error for f6: 0.9269560308029808\n",
      "Mean squared error for all features: 0.6042020408402309\n"
     ]
    }
   ],
   "source": [
    "# get the mean squared error of each model\n",
    "f1mse = mean_squared_error(testY, f1pred)\n",
    "f2mse = mean_squared_error(testY, f2pred)\n",
    "f3mse = mean_squared_error(testY, f3pred)\n",
    "f4mse = mean_squared_error(testY, f4pred)\n",
    "f5mse = mean_squared_error(testY, f5pred)\n",
    "f6mse = mean_squared_error(testY, f6pred)\n",
    "allmse = mean_squared_error(testY, allpred)\n",
    "\n",
    "# print the mean squared error of each model\n",
    "print(\"Mean squared error for f1: \" + str(f1mse))\n",
    "print(\"Mean squared error for f2: \" + str(f2mse))\n",
    "print(\"Mean squared error for f3: \" + str(f3mse))\n",
    "print(\"Mean squared error for f4: \" + str(f4mse))\n",
    "print(\"Mean squared error for f5: \" + str(f5mse))\n",
    "print(\"Mean squared error for f6: \" + str(f6mse))\n",
    "print(\"Mean squared error for all features: \" + str(allmse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Q14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train model from the onehot encoded C0 split nominal features (now all binary)\n",
    "x_c0 = df_merged[['C0_divorced', 'C0_married', 'C0_single', 'C0_facto union', 'C0_legally separated', 'C0_widower']]\n",
    "y_c0 = df_merged['regression target']\n",
    "trainX_c0, testX_c0, trainY_c0, testY_c0 = train_test_split(x_c0, y_c0, test_size=0.2, random_state=4211)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a linear regression model for C0\n",
    "C0model = linear_model.LinearRegression()\n",
    "C0reg = C0model.fit(trainX_c0, trainY_c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score for C0: 0.002965640471848774\n"
     ]
    }
   ],
   "source": [
    "# get the prediction\n",
    "C0pred = C0reg.predict(testX_c0)\n",
    "\n",
    "# get the r^2 score\n",
    "C0r2 = r2_score(testY_c0, C0pred)\n",
    "\n",
    "# print the r^2 score\n",
    "print(\"R^2 score for C0: \" + str(C0r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for C0: 0.9248007056329399\n"
     ]
    }
   ],
   "source": [
    "# get the mean squared error\n",
    "C0mse = mean_squared_error(testY, C0pred)\n",
    "\n",
    "# print the mean squared error\n",
    "print(\"Mean squared error for C0: \" + str(C0mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ffnn models\n",
    "mlp1 = MLPRegressor(hidden_layer_sizes=(1,1,1), early_stopping=True)\n",
    "mlp2 = MLPRegressor(hidden_layer_sizes=(8,8,8), early_stopping=True)\n",
    "mlp3 = MLPRegressor(hidden_layer_sizes=(32,32,32), early_stopping=True)\n",
    "mlp4 = MLPRegressor(hidden_layer_sizes=(128,128,128), early_stopping=True)\n",
    "\n",
    "H = [1, 8, 32, 128]\n",
    "rscores = []\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time taken for model 1: 0.5829554398854574\n",
      "Standard deviation of Time taken for model 1: 0.2674871914094547\n",
      "Mean R^2 score for model 1: 0.22964324646426792\n",
      "Standard deviation of R^2 score for model 1: 0.16377891446363466\n"
     ]
    }
   ],
   "source": [
    "tempr = []\n",
    "temptime = []\n",
    "for i in range(3):\n",
    "    # train model 1 and get its training time\n",
    "    start = time.time()\n",
    "    mlp1.fit(trainX, trainY)\n",
    "    end = time.time()\n",
    "    temptime.append(end - start)\n",
    "    # make predictions\n",
    "    mlp1pred = mlp1.predict(testX)\n",
    "    # get r^2 score\n",
    "    mlp1r2 = r2_score(testY, mlp1pred)\n",
    "    tempr.append(mlp1r2)\n",
    "# print time taken & r2 score\n",
    "meanrscore = np.mean(tempr)\n",
    "sdr = np.std(tempr)\n",
    "elapsed_time = np.mean(temptime)\n",
    "times.append(elapsed_time)\n",
    "sdtime = np.std(temptime) \n",
    "rscores.append(meanrscore)\n",
    "print(\"Mean Time taken for model 1: \" + str(elapsed_time))\n",
    "print(\"Standard deviation of Time taken for model 1: \" + str(sdtime))\n",
    "print(\"Mean R^2 score for model 1: \" + str(meanrscore))\n",
    "print(\"Standard deviation of R^2 score for model 1: \" + str(sdr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time taken for model 2: 0.2043320337931315\n",
      "Standard deviation of Time taken for model 2: 0.10491688434062109\n",
      "Mean R^2 score for model 2: 0.3703320479358287\n",
      "Standard deviation of R^2 score for model 2: 0.021219390687395433\n"
     ]
    }
   ],
   "source": [
    "tempr = []\n",
    "temptime = []\n",
    "for i in range(3):\n",
    "    # train model 2 and get its training time\n",
    "    start = time.time()\n",
    "    mlp2.fit(trainX, trainY)\n",
    "    end = time.time()\n",
    "    temptime.append(end - start)\n",
    "    # make predictions\n",
    "    mlp1pred = mlp2.predict(testX)\n",
    "    # get r^2 score\n",
    "    mlp2r2 = r2_score(testY, mlp1pred)\n",
    "    tempr.append(mlp2r2)\n",
    "# print time taken & r2 score\n",
    "meanrscore = np.mean(tempr)\n",
    "sdr = np.std(tempr)\n",
    "elapsed_time = np.mean(temptime)\n",
    "times.append(elapsed_time)\n",
    "sdtime = np.std(temptime) \n",
    "rscores.append(meanrscore)\n",
    "print(\"Mean Time taken for model 2: \" + str(elapsed_time))\n",
    "print(\"Standard deviation of Time taken for model 2: \" + str(sdtime))\n",
    "print(\"Mean R^2 score for model 2: \" + str(meanrscore))\n",
    "print(\"Standard deviation of R^2 score for model 2: \" + str(sdr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time taken for model 3: 0.25440144538879395\n",
      "Standard deviation of Time taken for model 3: 0.03128145123521301\n",
      "Mean R^2 score for model 3: 0.3790031886624224\n",
      "Standard deviation of R^2 score for model 3: 5.551115123125783e-17\n"
     ]
    }
   ],
   "source": [
    "tempr = []\n",
    "temptime = []\n",
    "for i in range(3):\n",
    "    # train model 3 and get its training time\n",
    "    start = time.time()\n",
    "    mlp3.fit(trainX, trainY)\n",
    "    end = time.time()\n",
    "    temptime.append(end - start)\n",
    "    # make predictions\n",
    "    mlp3pred = mlp3.predict(testX)\n",
    "    # get r^2 score\n",
    "    mlp3r2 = r2_score(testY, mlp1pred)\n",
    "    tempr.append(mlp3r2)\n",
    "# print time taken & r2 score\n",
    "meanrscore = np.mean(tempr)\n",
    "sdr = np.std(tempr)\n",
    "elapsed_time = np.mean(temptime)\n",
    "times.append(elapsed_time)\n",
    "sdtime = np.std(temptime) \n",
    "rscores.append(meanrscore)\n",
    "print(\"Mean Time taken for model 3: \" + str(elapsed_time))\n",
    "print(\"Standard deviation of Time taken for model 3: \" + str(sdtime))\n",
    "print(\"Mean R^2 score for model 3: \" + str(meanrscore))\n",
    "print(\"Standard deviation of R^2 score for model 3: \" + str(sdr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time taken for model 4: 1.1119808355967205\n",
      "Standard deviation of Time taken for model 4: 0.630263321187976\n",
      "Mean R^2 score for model 4: 0.4027646595813678\n",
      "Standard deviation of R^2 score for model 4: 0.008610459111680962\n"
     ]
    }
   ],
   "source": [
    "tempr = []\n",
    "temptime = []\n",
    "for i in range(3):\n",
    "    # train model 4 and get its training time\n",
    "    start = time.time()\n",
    "    mlp4.fit(trainX, trainY)\n",
    "    end = time.time()\n",
    "    temptime.append(end - start)\n",
    "    # make predictions\n",
    "    mlp4pred = mlp4.predict(testX)\n",
    "    # get r^2 score\n",
    "    mlp4r2 = r2_score(testY, mlp4pred)\n",
    "    tempr.append(mlp4r2)\n",
    "# print time taken & r2 score\n",
    "meanrscore = np.mean(tempr)\n",
    "sdr = np.std(tempr)\n",
    "elapsed_time = np.mean(temptime)\n",
    "times.append(elapsed_time)\n",
    "sdtime = np.std(temptime) \n",
    "rscores.append(meanrscore)\n",
    "print(\"Mean Time taken for model 4: \" + str(elapsed_time))\n",
    "print(\"Standard deviation of Time taken for model 4: \" + str(sdtime))\n",
    "print(\"Mean R^2 score for model 4: \" + str(meanrscore))\n",
    "print(\"Standard deviation of R^2 score for model 4: \" + str(sdr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the rscores to H values\n",
    "plt.plot(H, rscores)\n",
    "plt.xlabel('Number of hidden units')\n",
    "plt.ylabel('Mean R2 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most efficient NN Mean R^2 score: 0.3790031886624224\n",
      "Mean Time taken: 0.25440144538879395\n",
      "Linear Regression R^2 score: 0.34860539017166103\n",
      "Linear Regression Time taken: 0.0016407966613769531\n"
     ]
    }
   ],
   "source": [
    "# print info to compare with lin reg\n",
    "print(\"Most efficient NN Mean R^2 score: \" + str(rscores[2]))\n",
    "print(\"Mean Time taken: \" + str(times[2]))\n",
    "print(\"Linear Regression R^2 score: \" + str(allr2))\n",
    "print(\"Linear Regression Time taken: \" + str(linear_reg_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the train and test data\n",
    "x = df_selected.drop(columns=['classification target', 'regression target'])\n",
    "y = df_selected['classification target']\n",
    "trainX, testX, trainY, testY = train_test_split(x, y, test_size=0.2, random_state=4211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a logistic regression model using gradient-descending algorithm and a step size parameter of 0.2.\n",
    "logreg = SGDClassifier(loss='log_loss', learning_rate='optimal', eta0=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time taken: 0.03864638010660807 Standard deviation: 0.0033449998875587916\n",
      "Mean Accuracy: 0.8592278719397363 Standard deviation: 0.006951423286362226\n",
      "Mean F1 score: 0.9012658432782242 Standard deviation: 0.006971410059145111\n"
     ]
    }
   ],
   "source": [
    "# train the model and get the mean time taken\n",
    "temptimes = []\n",
    "tempacc = []\n",
    "tempF1 = []\n",
    "for i in range(3):\n",
    "    start = time.time()\n",
    "    logreg.fit(trainX, trainY)\n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    prediction = logreg.predict(testX)\n",
    "    temptimes.append(elapsed_time)\n",
    "    tempacc.append(accuracy_score(testY, prediction))\n",
    "    tempF1.append(f1_score(testY, prediction))\n",
    "# get the mean time, accuracy and F1 score\n",
    "lr_mean_time = np.mean(temptimes)\n",
    "lr_mean_acc = np.mean(tempacc)\n",
    "lr_mean_f1 = np.mean(tempF1)\n",
    "# get the standard deviation of time, accuracy and F1 score\n",
    "sd_time = np.std(temptimes)\n",
    "sd_acc = np.std(tempacc)\n",
    "sd_f1 = np.std(tempF1)\n",
    "# print the results\n",
    "print(\"Mean Time taken: \" + str(lr_mean_time) + \" Standard deviation: \" + str(sd_time))\n",
    "print(\"Mean Accuracy: \" + str(lr_mean_acc) + \" Standard deviation: \" + str(sd_acc))\n",
    "print(\"Mean F1 score: \" + str(lr_mean_f1) + \" Standard deviation: \" + str(sd_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAHPCAYAAABUVg6YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkOklEQVR4nO3dd1iTZ/s38G9ANgKiOJEi+BAnWqsiYlFxAtZJcW8rtrTW1Tra11FHra1aAatWqyhVHLVuwNlqldY6q491QnFhUUEZMgLJ/f7BL3mMAQwhCQn5fo7DQ3PdI+d9geTkmiJBEAQQERERmRizyg6AiIiIqDIwCSIiIiKTxCSIiIiITBKTICIiIjJJTIKIiIjIJDEJIiIiIpPEJIiIiIhMEpMgIiIiMklMgoiIiMgkMQkiIq0KCAjArFmzKjsMIqLXqlbZARCR+n7++WfMnj1b8drc3Bw1a9aEn58fpk6dijp16lRidIZLLBYrvbazs0OzZs0wYcIEdOnSpcRrbt++jXXr1uHs2bN49uwZnJyc4OPjg0mTJuE///lPidfcu3cPGzZswJkzZ/D48WNYWFjAy8sLgYGBGDx4MKytrV8b69mzZxETE4NLly4hMzMT1atXR6tWrTBw4ED07Nmz3M9ORKUTce8wIuMhT4ImT54MV1dXSCQSXL58GXv27EGDBg1w8OBBWFlZVWqMEokEIpEIFhYWlRrHy8RiMfz8/NCvXz8IgoDU1FTExsbiyZMnWL9+Pd5++22l848cOYJp06bByckJgwYNgqurKx4+fIiffvoJz58/x8qVK9GjRw+la3799Vd8/PHHsLS0RL9+/eDl5YXCwkJcuHABR44cwYABA7Bw4cIy44yIiMDq1avh7u6O4OBg1K9fH8+fP8fJkyfx559/4ptvvsE777yj9fohMlkCERmN3bt3C15eXsKVK1eUyr/++mvBy8tLOHToUCVFVrny8/MFqVRa6nEvLy9hwYIFSmV37twRvLy8hAkTJiiV3717V2jVqpXQu3dvIT09XelYenq60Lt3b6F169bCvXv3FOX37t0TWrduLfTu3VtIS0tTef+UlBQhOjq6zGeIj48XvLy8hI8++kiQSCQqx0+dOiWcOHGizHuoKzc3Vyv3ITJ2HBNEVAW0bdsWAHD//n2l8qSkJEyePBnt27dHy5YtMXDgQBw/flzl+qysLCxZsgQBAQFo0aIF/P398emnnyIjI0NxjkQiQUREBHr06IEWLVqgc+fOWLZsGSQSidK9Xh4TdPXqVYjFYuzZs0flPX/77TeIxWL88ssvirK0tDTMnj0bHTt2RIsWLRAcHIyffvpJ6bqzZ89CLBbj0KFDWLlyJd5++220atUKOTk55aozT09P1KhRA/fu3VMq37BhA/Ly8rBw4UI4OzsrHXN2dsYXX3yB3NxcrF+/Xuma3NxcLF68GLVr11Z5rzfeeAOjR48uM55Vq1bByckJS5YsKbEV7e2330bXrl0BFLcIisViPHjwQOkced2cPXtWUTZy5Ej06dMH//3vfzF8+HC0atUKK1asQFhYGLp161ZiLIMHD8bAgQOVyvbt24eBAwfC29sb7du3x9SpU/Ho0aMyn4nI0HFMEFEV8PDhQwCAg4ODouz27dsYOnQo6tSpg/feew+2traIj49HeHg4IiMjFd05L168wPDhw5GUlIRBgwahWbNmePbsGU6cOIG0tDQ4OztDJpPh/fffx4ULFxAaGgpPT0/cunULmzdvRkpKCr777rsS42rZsiUaNmyI+Ph4DBgwQOlYXFwcHB0d0alTJwDA06dPERoaCpFIhOHDh8PZ2RmnTp3CZ599hpycHIwZM0bp+u+++w4WFhYYP348JBJJubvfsrOzkZWVBTc3N6XyX375BQ0aNFAklq9q164dGjRogJMnTypd07BhQ7Rp06ZcMcilpKQgOTkZgwYNgr29vUb3KMvz58/x3nvvITg4GH379kXNmjXRvHlzzJw5E1euXIG3t7fi3IcPH+Ly5cv49NNPFWVr1qzBqlWrEBgYiJCQEGRkZODHH3/E8OHDsXfvXqXvOyJjwiSIyAjl5OQgIyMDEokEf/31F6KiomBpaaloKQCAxYsXo169eti9ezcsLS0BAMOGDcPQoUPxzTffKJKgH374Abdu3UJUVJTSOJcPPvgAwv8NGTxw4AASExMRExOjlBz85z//wbx583Dx4sVSE4CgoCBs3LgRmZmZcHR0BFDcqnTs2DH06NFDkbysXLkSUqkUBw4cQI0aNQAAQ4cOxbRp0xAVFYUhQ4YoDSwuKCjA7t271RpsLD9f3rKVmpqKb7/9FlKpFL169VKck52djcePH5faQiInFotx4sQJRetTWlraa68pS1JSEgDAy8tL43uU5cmTJ1iwYAGGDBmiKMvJyYGlpSXi4+OVkqD4+HiIRCIEBgYCKE6KIiMjMWXKFEyaNElxXs+ePTFgwABs27ZNqZzImLA7jMgIjRkzBr6+vujcuTMmT54MGxsbrFmzBnXr1gVQ/Jv/H3/8gcDAQEXClJGRgWfPnqFTp05ISUlBWloagOJBwE2aNFEZ6AsAIpEIAJCQkABPT094eHgo7pWRkYEOHToAgFL3y6uCgoJQWFiII0eOKMrOnDmDrKwsBAUFAQAEQcCRI0cQEBAAQRCU3qNTp07Izs7GtWvXlO7bv39/tRMgAPjpp5/g6+sLX19fDBo0CH/88QcmTJiAsWPHKs558eIFgOLZY2WRH3/x4oUiEXrdNWXRxj3KYmlpqdK9ZW9vD39/f8THxyuSXaC4ha5169aoX78+AODo0aOQyWQIDAxU+rrUqlULb7zxRplfeyJDx5YgIiM0d+5cNGrUCNnZ2di9ezfOnTunaO0BiqdqC4KAVatWYdWqVSXeIz09HXXq1MG9e/deO/X67t27SEpKgq+vb6n3Kk2TJk3g4eGB+Ph4vPvuuwCKP2hr1KihSKIyMjKQlZWFHTt2YMeOHSXe5+XxSQDg6upaZsyv6tatG0aMGIHCwkJcvXoVa9euRX5+PszM/ve74MvJTVlKSpZed01Z5F1gFblHWerUqaP0/SEXFBSEY8eO4dKlS2jTpg3u3buHa9euYc6cOYpzUlJSIAhCqd8j1arxY4SMF797iYyQt7c3WrZsCQDo3r07hg0bhunTpyMhIQF2dnaQyWQAgHHjxqlM/5Z7dSxMWWQyGby8vJTWKHqZvAWqNEFBQVi7di0yMjJgb2+PEydOIDg4WPEBKo+3b9++KmOH5F5d66c8rUDyGDt27AgA6Ny5M2rUqIEvvvgCPj4+ig/46tWrw8XFBTdv3izzXjdv3kSdOnUUyUvt2rVx+/btcsXzMg8PDwDArVu31Dpf3kL3Knk9vqq0uuratStsbGwQHx+PNm3aID4+HmZmZujdu7fSPUUiEdavXw9zc3OVe9ja2qoVM5EhYhJEZOTMzc0xbdo0jBo1Clu3bsXEiRPRsGFDAICFhYXig780bm5ur/0Ad3Nzw40bN+Dr61vqB3BZgoKCEBUVhSNHjqBWrVrIyclBcHCw4rizs7MieXtdvNoyePBgREdH49tvv0WPHj0Uz9W1a1fs3LkT58+fL3Fw9Pnz5/Hw4UMMHjxYUda1a1fs2LEDly5dwptvvlnuWBo1aoRGjRrh+PHjePHixWu7xeQDkbOzs5XK5QPk1WVra4suXbogISEBs2fPRlxcHNq2bau06KabmxsEQYCrqysaNWpUrvsTGTqOCSKqAnx8fODt7Y3NmzejoKAANWvWRPv27bFjxw48fvxY5fyXu5Z69uyJGzdu4OjRoyrnyceKBAYGIi0tDTt37lQ5Jz8/H7m5uWXG5+npCS8vL8TFxSEuLg4uLi5o166d4ri5uTl69eqFw4cPl9ga8mpXmDZUq1YNY8eORVJSktKyAePHj4e1tTXmzZuHZ8+eKV3z/PlzzJs3DzY2NpgwYYKifMKECbC1tcXnn3+Op0+fqrzXvXv3sHnz5jLjmTx5Mp4/f47PP/8cRUVFKsdPnz6tWE5A3op37tw5xXGpVFri1+d1goKC8PjxY+zatQs3btxQDIiW69mzJ8zNzREVFaU0dggo/v54tY6IjAlbgoiqiPHjx+Pjjz/Gzz//jKFDh2LevHkYNmwY3nnnHYSGhqJhw4Z4+vQpLl++jH///Rf79+9XXHf48GF8/PHHGDRoEJo3b47MzEycOHECCxYsQJMmTdCvXz/Ex8dj3rx5OHv2LNq0aQOpVIrk5GQkJCRgw4YNiu650gQFBSEiIgJWVlYICQlRGosDANOnT8fZs2cRGhqKd999F40bN0ZmZiauXbuG33//HX/++afW62zgwIGIiIjA+vXr0b17dwCAu7s7li5dik8++QTvvPMOQkJClFaMfvbsGVasWKHUnejm5oZvvvkGU6dORVBQkGLFaIlEgkuXLiEhIUFlYHJJ9XPz5k2sXbsWf//9N/r06aNYMfq3337D77//juXLlwMonpXXunVrrFixQjHrLi4ursTk6XU6d+4MOzs7fPXVV4pk9GVubm6YMmUKli9fjocPH6J79+6ws7PDgwcPcOzYMYSGhmL8+PHlfl8iQ8AkiKiK6NmzJ9zc3LBx40aEhoaicePG2L17N6KiorBnzx48f/4czs7OaNasGcLDwxXX2dnZYevWrYiMjMTRo0exZ88e1KxZE76+vopuETMzM6xevRrR0dHYt28fjh49ChsbG7i6umLkyJFqdZMEBQXh22+/RV5enkprAwDUqlULu3btwurVq3H06FHExsbCyckJjRs3xowZM7RXUS+xtrbGiBEjEBkZibNnz8LHxwdAccuXh4cHvv/+e8VWGfK9w8LCwkqcyt6tWzfs378fP/zwA44fP47Y2FhYWlpCLBZj1qxZCA0NfW08U6dORYcOHRATE4PY2FhkZmbCwcEBrVq1wnfffac0Df+bb77B3Llz8f3338PBwQEhISHw8fFRmu2mDisrKwQEBODAgQPo2LEjatasqXLOxIkT4e7ujujoaKxevRpA8RgrPz8/BAQElOv9iAwJ9w4jIiIik8QxQURERGSSmAQRERGRSWISRERERCaJSRARERGZJCZBREREZJKYBBEREZFJ4jpBpbh06RIEQYCFhUVlh0JERERqKiwshEgkUmsLG7YElUIQBJUl4rV5b4lEorP7UzHWs36wnvWD9awfrGf90GU9l+fzmy1BpZC3AL1uKwBN5Obm4vr162jcuDF3YNYh1rN+sJ71g/WsH6xn/dBlPV+9elXtc9kSRERERCaJSRARERGZJCZBREREZJKYBBEREZFJYhJEREREJolJEBEREZkkJkFERERkkpgEERERkUliEkREREQmyaCSoLt372Lu3Lno168fmjVrhj59+qh1nSAI+P7779GlSxd4e3tj8ODBuHz5sm6DJSIiIqNmUEnQ7du3cfLkSbzxxhvw9PRU+7r169cjIiICY8aMwbp16+Di4oJx48bh/v37OoyWiIiIjJlBJUEBAQE4efIkIiIi0Lx5c7WuKSgowLp16zBu3DiMGTMGvr6+WLFiBZycnPDDDz/oOGIiIiIyVga1gaqZWflzsosXLyInJweBgYGKMktLS/To0QNHjx7VZnhERERGSxAEFEiklR0GACBfItXJDvLlZVBJkCaSk5MBAB4eHkrlnp6e2Lx5M/Lz82Ftba3RvQVBQG5uboVjfFVeXp7S36QbrGf9YD3rliAIKCiUIT8vD5IiGZ5n5iDfQD7IqqIqW8+CgHkbziPl3+zKjkShoYslvnDX/mesIAgQiURqnWv0SVBWVhYsLS1hZWWlVO7g4ABBEJCZmalxElRYWIjr169rI8wSpaSk6Oze9D+sZ/2oKvUsCAIKpZX/GyoACAKw6dgT/Pus8KXS1EqLx7SwnvUhJSVF7YSlPCwtLdU6z+iTIF2ysLBA48aNtX7fvLw8pKSkwN3dHTY2Nlq/PxVjPetHVapnQRAwd8M53LqXWdmhEOmEe93qWDChLaCDxKM88vPykPrwHho1aqT1nxt37txR+1yjT4IcHBwgkUhQUFCg1BqUlZUFkUgER0dHje8tEolga2urjTBLZGNjo9P7UzHWs34YWz2XND4iXyI1yATIo74j5o1rg5u3bkIsbgJbI082DVluXh5u3rxRZevZytJcJy0v5ZVraY5HqSKd/Nwoz/MZfRIkHwv0zz//oEmTJory5ORk1K9fX+OuMCIybmUNAhUAzIo6jeTU0hOemPm9YW1prqPoysfK0hx5eXmwrGYGa0tzWFsZ/Y9ugyWTmrOeTYjRf4XbtGkDe3t7xMfHK5KgwsJCHDlyBP7+/pUcHRHJ6XNmijpJTlmaujvD0d7SIH5jJiLdMagkKC8vDydPngQAPHz4EDk5OUhISAAAtG/fHs7Ozhg9ejRSU1MV09+trKwQFhaGyMhIODs7w8vLC7GxsXj+/DnGjx9fac9CZGoEQUB+QVHJx1CxpERXPOo7YumHnfBqqmMoXQZEpFsGlQSlp6fj448/ViqTv96yZQt8fHwgk8kglSr/Nvnee+9BEARs3LgRGRkZaNq0KX744Qc0bNhQb7ETmTJDHVBcWpIjx2SHyLQZVBLk6uqKmzdvlnlOTEyMSplIJEJYWBjCwsJ0FRqRSSlP11W+RIoXBTK1EqDXJSXaxiSHiMpiUEkQEVU+QRAwM+o0rqdkaHR9WQOKmZQQkSFhEkRESi0/+RKpxgkQBxQTkTFhEkRk4spq+VFnmvjL66rUcLRnAkRERoNJEJGJKyil5UfdVp2X11VhAkRExoRJEJEJerX7S+7llh+O3yGiqo5JEFEVVtIsr7LW7OEquURkSvjTjqgKeTnpKe8ChU3dnWFlINtEEBHpA5MgIiMnT3zKm/S8umYPu7+IyNQwCSIyEuXt2pLj1hBERCVjEkRk4ARBQL5EqnYrD1t4iIjUwySIyECVJ/l5OfFh0kNEpB4mQUQGpqzkh11bRETawySIyICUtnqzPPnhgoRERNrDJIjIgLy6ejOTHyIi3WESRGQg5N1gcjHze3MzUiIiHWISRFRJXrewIVt/iIh0i0kQUSUoa+d2gKs3ExHpA5MgokpQ2s7tHANERKQ/TIKI9ODV1Z65czsRUeVjEkSkY6/r+uLO7URElcOssgMgqupK6/oCOPaHiKgy8ddPIj16uesLYPcXEVFlYhJEpAMvjwF6efwPu76IiAwHfxoTaVF5d3wnIqLKwySISEu49g8RkXFhEkRUAa92e5W075d8xA/H/xARGRYmQUQaeF23F/f9IiIyfEyCiMpJnW4vJkBERIaPSRBROQiCgMwcCbu9iIiqACZBRGoqqQWI3V5ERMaLK0YTqenVlZ/Z7UVEZNzYEkSkAbYAEREZP7YEEWnAmuN+iIiMHluCiF7x8to/L8svoYyIiIwXkyCil7xu+jsREVUd7A4j+j8lTX8vCbe/ICKqGtgSRITSp79bl5DscB0gIqKqgUkQmayy9v3i9HcioqqPSRCZpLLG/nD6OxGRaeCYIDJJry58KMcWICIi08GWIDJ5L4/94XgfIiLTwSSITJ61pTmsrfhfgYjI1LA7jIiIiEwSkyAiIiIySewDIJPx6pR4IiIybUyCqMoTBAF5BUWYFXUayamZlR0OEREZCCZBVOXIW3zyJVIUFMow67uzSPk3u8RzuQUGEZHpYhJEVYYgCMiXSMts8fGo74ilH3aCfBI8p8QTEZkuJkFUJbxu93d58mPNpIeIiP4PkyCqEl5dAdqjviPmjWuDm7duQixughqO9kx+iIhICZMgqnLke3/l5eXBspoZW3+IiKhEXCeIqhwmPUREpA4mQURERGSS2B1GRu3l6fBERETlYXBJUFJSEhYtWoRLly7Bzs4O/fr1w5QpU2BpaVnmdc+ePcPKlStx6tQpPH/+HK6urhg+fDiGDh2qp8hJ3143I4yIiKgsBpUEZWZmYvTo0XB3d0dkZCTS0tKwdOlS5OfnY+7cuWVe+/HHHyM5ORnTpk1DvXr1cOrUKcyfPx/m5uYIDQ3V0xOQPr06Iwzg4odERKQ+g0qCtm/fjhcvXiAqKgpOTk4AAKlUigULFiAsLAx16tQp8bonT57g7Nmz+PLLLzFw4EAAgK+vL65evYpDhw4xCTIBMfN7w9rSnIsfEhGR2gxqYPSpU6fg6+urSIAAIDAwEDKZDGfOnCn1uqKiIgBA9erVlcrt7e0hCIJOYqXKJV8dWs7a0hzWVtWYABERkdoMKglKTk6Gh4eHUpmDgwNcXFyQnJxc6nX16tVDp06dsHbtWty5cwc5OTmIi4vDmTNnMHz4cF2HTXomHws0cn5CZYdCRERGzKC6w7KysuDg4KBS7ujoiMzMsnf/joyMxNSpUxEcHAwAMDc3x+eff45evXppHI8gCMjNzdX4+tLk5eUp/U2vJwgCCgplAFTHAondnCAtKkCuVKJ0DetZP1jP+sF61g/Ws37osp4FQVC7V8CgkiBNCYKA2bNnIyUlBcuXL4eLiwsSExOxZMkSODo6KhKj8iosLMT169e1HO3/pKSk6OzeVYkgCNh49AnuP5WoHJsxsB7srMxw48aNUq9nPesH61k/WM/6wXrWD13V8+tmlMsZVBLk4OCA7OxslfLMzEw4OjqWet2vv/6KhIQE7N+/H2KxGADg4+OD9PR0LF26VOMkyMLCAo0bN9bo2rLk5eUhJSUF7u7usLGx0fr9qxJBEJD1ohD3nz5UOSZ2c0Lb1s1LzfhZz/rBetYP1rN+sJ71Q5f1fOfOHbXPNagkyMPDQ2XsT3Z2Np48eaIyVuhld+7cgbm5Oby8vJTKmzZtil27diEvL0+jShaJRLC1tS33deqysbHR6f2NXUnrAMlngQFQeyYY61k/WM/6wXrWD9azfuiinsszQcagBkb7+/sjMTERWVlZirKEhASYmZnBz8+v1OsaNGgAqVSKmzdvKpVfu3YNNWvWZDZvpF4d+9PU3RmO9pawtqrGmWBERFRhBtUSNGTIEMTExCA8PBxhYWFIS0vDsmXLMGTIEKU1gkaPHo3U1FQcPXoUQHHyVL9+fUyePBnh4eGoXbs2Tp8+jT179uCjjz6qrMchLZLvDM/Eh4iItMWgkiBHR0ds3rwZCxcuRHh4OOzs7BASEoKpU6cqnSeTySCV/m+NGHt7e0RHR2PlypX45ptvkJ2dDVdXV8yaNQsjRozQ92OQDnBneCIi0jaDSoIAwNPTE9HR0WWeExMTo1L2xhtv4Ntvv9VNUERERFTlGNSYICIiIiJ9YRJEREREJolJEBEREZkkJkFkkF7dIJWIiEjbDG5gNFFJiyQSERFpG5MgMgiCIKDg/1p+8ktYJNHq/1aJJiIi0hYmQVTpymr54SKJRESkKxwTRJXu1e0x5OTbZDABIiIiXWBLEBkUTTZIJSIi0gSTIDIo1pbmsLbityUREekeu8OIiIjIJDEJIiIiIpPEJIgqFRdFJCKiysLBF1RpuCgiERFVJrYEUaV5dWo8F0UkIiJ9YksQGQQuikhERPrGliAyCNZcE4iIiPSMSRARERGZJCZBREREZJKYBBEREZFJYhJEREREJqlCs8MkEgmuXbuG9PR0tGnTBs7OztqKi4iIiEinNG4J2rJlCzp16oRhw4bho48+ws2bNwEAGRkZ8PHxwU8//aS1IMm4CYKA/IIi1T9cKZqIiCqRRi1Bu3fvxpIlSxAcHAw/Pz/MmTNHcczZ2RkdOnRAXFwcQkJCtBYoGSeuCk1ERIZKo5agTZs2oVu3bli+fDm6du2qcrx58+a4fft2hYMj4/fqqtAl4UrRRERUGTRqCbp79y5GjhxZ6nEnJyc8f/5c05ioinh1c9SY+b1hXUKyY8WFEomIqBJolAQ5ODjg2bNnpR6/c+cOXFxcNA6KjF9J3WDWluawtuJOLUREZBg06g7z9/fHzp07kZWVpXLs9u3b2LVrFwICAiocHBkvbo5KRESGTqNfy6dMmYLQ0FD06dMHXbt2hUgkwt69e7F7924cOXIELi4u+OCDD7QdKxkpbo5KRESGSKOWoDp16uDnn3/G22+/jfj4eAiCgH379uGXX35BcHAwdu7cyTWDSIGboxIRkSHSeIBGzZo1sXjxYixevBgZGRmQyWRwdnaGmRkXoSYiIiLDp1HGMnv2bPz111+K187OzqhVq5YiAbpy5Qpmz56tnQiJiIiIdECjJGjPnj24d+9eqccfPHiAvXv3ahoTERERkc7ppO/q8ePHsLa21sWtiYiIiLRC7TFBx44dw/HjxxWvd+7cicTERJXzsrOzkZiYiBYtWmgnQiIiIiIdUDsJSkpKQkJCAgBAJBLhr7/+wn//+1+lc0QiEWxtbdGuXTvMmjVLu5ESERERaZHaSVBYWBjCwsIAAE2aNMHixYvxzjvv6CwwIiIiIl3SaIr8jRs3tB0HVSGv7hlGRERkiLiRE2lVSXuGERERGSKNk6CTJ08iOjoaf//9N7KzsyEIgso5169fr1BwZHy4ZxgRERkLjZKgw4cPY8qUKWjcuDGCgoIQGxuLPn36QBAEnDhxAm+88Qa6d++u7VjJyHDPMCIiMmQaJUHr1q2Dt7c3tm3bhszMTMTGxmLQoEHw9fXFgwcPMHjwYLi6umo7VjIy3DOMiIgMmUaLJSYlJSEoKAjm5uaoVq04jyoqKgIAuLq6YujQoVi/fr32oiQiIiLSMo2SIGtra1hYWAAAHBwcYGlpiSdPniiO16pVCw8ePNBOhEREREQ6oFES1KhRIyQlJSleN23aFPv27UNRUREKCgpw8OBB1KtXT2tBEhEREWmbRklQjx49cPz4cUgkEgDApEmT8Oeff6Jdu3bo0KEDzp8/j4kTJ2o1UDJ8XB+IiIiMiUYDo8ePH4/x48crXnft2hUxMTE4cuQIzM3N0blzZ3To0EFrQZLh4/pARERkbLS2WGLbtm3Rtm1bxeucnBzY29tr6/Zk4Lg+EBERGRutrxidnp6OzZs3IzY2FufOndP27ckIcH0gIiIyBuVKgtLT07F3717cu3cPjo6O6NmzJ1q0aAEASEtLw5o1a7Bnzx4UFBSgffv2OgmYDB/XByIiImOgdhKUlJSEESNG4Pnz54otMjZs2ICvv/4aIpEIn332GSQSCXr27Inx48crkiMiIiIiQ6R2ErRq1Srk5uZi3rx5aNu2LR48eIAvv/wSS5YsQXZ2Nrp27YoZM2agYcOGuoyXiIiISCvUToLOnz+PoUOHYsiQIQCAxo0bw9zcHO+99x4GDBiAL7/8UmdBEhEREWmb2usEPX/+HGKxWKmsSZMmAMDNUomIiMjoqJ0EyWQyxT5hcvLXtra22o2KiIiISMfKNTvsv//9L6ysrBSvX7x4AZFIhAsXLiA7O1vl/J49e5Y7oKSkJCxatAiXLl2CnZ0d+vXrhylTpsDS0vK116alpWHFihU4efIkcnNz0aBBA7z//vvo27dvueMgIiKiqq1cSdDmzZuxefNmlfKoqCiVMpFIhOvXr5crmMzMTIwePRru7u6IjIxEWloali5divz8fMydO7fMax8/fozBgwejUaNGWLhwIezt7XH79m3F1h5EREREL1M7CdqyZYsu4wAAbN++HS9evEBUVBScnJwAAFKpFAsWLEBYWBjq1KlT6rVff/016tatiw0bNsDcvHilYl9fX53HTERERMZJ7SRIH4sfnjp1Cr6+vooECAACAwMxb948nDlzBgMHDizxupycHMTHx2PJkiWKBIiIiIioLFrfNqMikpOTMWjQIKUyBwcHuLi4IDk5udTrrl27hsLCQlSrVg0jRozApUuX4OTkhP79+2PKlCmwsLDQKB5BEJCbm6vRtWXJy8tT+rsqeHn3+Ny8PMiklZ+MVsV6NkSsZ/1gPesH61k/dFnPgiCovWuBQSVBWVlZcHBwUCl3dHREZmZmqdc9ffoUAPD5558jNDQUH374Ia5cuYKIiAiYmZlh+vTpGsVTWFhY7nFN5ZGSkqKze+ubpEim+PfNmzdgWU3tiYc6V5Xq2ZCxnvWD9awfrGf90FU9qzOZCjCwJEhTMlnxB3DHjh0xa9YsAECHDh3w4sULbNy4EeHh4bC2ti73fS0sLNC4cWOtxgoUZ74pKSlwd3eHjY2N1u9fGYpbglIBAGJxE1gbwA7yVbGeDRHrWT9Yz/rBetYPXdbznTt31D7XoJIgBweHEqfaZ2ZmwtHRsczrgOLE52W+vr5Yu3Yt7t69q7LQozpEIpFO10CysbGpMmssmZkXKf5ta2MDayvD+daqSvVsyFjP+sF61g/Ws37oop7Ls4G34fRZAPDw8FAZ+5OdnY0nT57Aw8Oj1Ote11pTUFCglfiIiIio6jCoJMjf3x+JiYnIyspSlCUkJMDMzAx+fn6lXtegQQN4eXkhMTFRqTwxMRHW1tY66dIiIiIi46ZxEpSamoq5c+eiV69eaN++Pc6dOwcAyMjIwKJFi/D333+X+55DhgyBnZ0dwsPDcfr0aezevRvLli3DkCFDlNYIGj16NHr06KF07dSpU3HixAksXrwYZ86cwdq1a7Fx40aMGTOGTZpaJggC8guKlP+8NDuMiIjIGGg0cOPOnTsYPnw4ZDIZvL29ce/ePRQVFY8JcXZ2xoULF5Cbm4slS5aU676Ojo7YvHkzFi5ciPDwcNjZ2SEkJARTp05VOk8mk0EqVf7QDQgIwIoVK/Ddd98hNjYWtWvXxkcffYSJEydq8ohUCkEQMDPqNK6nZFR2KERERBWiURL09ddfo3r16ti5cyeA4llZL+vcuTPi4+M1CsjT0xPR0dFlnhMTE1NieVBQEIKCgjR6X1JPgURaZgLU1N0ZVgYwM4yIiOh1NEqCzp07h/DwcDg7O+PZs2cqx+vXr4+0tLQKB0eGLWZ+b5Wp8FaW5uUamU9ERFRZNEqCBEEoc92djIwMtRcqIuMhCILS2B9rS3ODmgpPRERUHhoNjG7WrBlOnjxZ4rGioiIcOnQIrVq1qlBgZDgEQUBeQRGmrDiJkfMTKjscIiIirdAoCZo4cSJ+++03zJs3D7dv3wYApKenIzExEePGjUNycjIHJFcR8oHQoXMOITn1f1uXcOwPEREZO436Mjp37owvv/wSS5YsUQyO/uSTTyAIAuzt7fHVV1+hXbt2Wg2UKserA6E96jti6YedYM2xP0REZOQ0HtDRv39/9OzZE4mJiUhJSYFMJoObmxs6deoEe3t7bcZIlUAQBBRIpEpjgGLm94ajvSWTHyIiqhI0Hhgt31ere/fu2o6JKllpawGx9YeIiKoSjcYEvf3221i0aBEuXLig7XiokgmCgMwciUoCxDFARERU1WjUEtS+fXvs3r0bW7duRZ06dRAYGIjAwEB4e3trOz7So5JagORrAXH9HyIiqmo0SoJWrFiB/Px8/PLLL4iPj0dsbCyio6PRoEEDBAUFITAwEE2bNtV2rKRjrw6CburuzDFARERUZWk8MNra2lrRApSbm4sTJ04gLi4O0dHRWL9+Pd544w0kJHBNGWPFQdBERFTVabyL/MtsbW3Rp08ffP311/j0009ha2uLu3fvauPWpGNKO8K/sho0EyAiIqrKKrznQV5eHk6cOIH4+Hj89ttvkEgkcHNzQ2BgoDbiIx3ijvBERGTKNEqCCgoK8OuvvyIuLg6nTp1CXl4eGjRogJEjRyIoKAjNmjXTdpykA6XtCM+ZYEREZAo0SoI6dOiA/Px81K5dG6GhoQgKCuJeYUbu5R3hOROMiIhMgUZJ0MCBAxEYGIi2bdtqOx6qJNwRnoiITI1Gn3r/7//9P23HQURERKRXaiVB586dAwDFpqjy16/DTVSJiIjIUKmVBI0cORIikQh//fUXLC0tFa9LI99b7Pr161oLlIiIiEib1EqCtmzZAgCwtLRUek1ERERkrNRKgtq3b1/mayIiIiJjo9GK0aNGjcLvv/9e6vE//vgDo0aN0jgoIiIiIl3TKAn6888/8fTp01KPZ2RkqD14moiIiKgyaLx3WFkDo+/evQs7OztNb01ERESkc2qvE7Rnzx7s2bNH8XrNmjXYuXOnynnZ2dm4efMm/P39tRMhERERkQ6onQTl5eXh2bNnitcvXryAmZlqQ5KtrS2GDBmC8PBw7URIREREpANqJ0HDhg3DsGHDAAABAQH47LPP0K1bN50FRkRERKRLGm2bceLECW3HQXomCALyJdLKDoOIiKjSqJUEpaamAgDq16+v9Pp15OeTYREEATOjTuN6SkZlh0JERFRp1EqCAgIClLbNkL9+HW6bYZgKJFKlBKipuzOsLM0rMSIiIiL9UysJWrJkCUQiESwsLJRek/F5tRssZn5vONpb8utJREQmR60kaODAgWW+JuNQUjeYtaU5EyAiIjJJGi+WWBKJRILc3Fxt3pK0iN1gRERE/6NREnTo0CEsWbJEqSwqKgpt2rRBu3btEB4ejhcvXmglQNKNmPm98dWHndgKREREJkujJGjjxo3Iy8tTvL548SKioqLQqVMnjB49Gr/99hvWrl2rtSBJ+9gNRkREpk6jdYLu37+PAQMGKF4fPHgQtWrVQlRUFKpVqwZBEHDkyBFMnz5da4FSxXBdICIiImUaJUESiQRWVlaK12fOnIG/vz+qVSu+naenJ7Zt26adCKnCuC4QERGRKo26w1xdXZGYmAgAuHr1Ku7evYu3335bcTw9PR22trbaiZAqjAOiiYiIVGnUEjR48GAsXrwYd+7cQVpaGurWrYuuXbsqjl+8eBGNGzfWWpCkPVwXiIiIqJhGSdDIkSNhZWWFkydPokWLFpgwYQKsra0BAM+fP8eTJ08wdOhQrQZK2sEB0URERMU0SoIAIDQ0FKGhoSrlTk5O+PnnnysUFBEREZGuaZwEyd25cwcPHz4EADRo0IDdYERERGQUNE6Cjh07hqVLlyoSIDlXV1fMmjUL3bp1q3BwVHGcGk9ERFQyjZKgkydPYvLkyahfvz6mTp0KT09PAEBSUhJ27tyJjz76CGvXroW/v79Wg6Xy4dR4IiKi0mmUBH333XcQi8XYunWr0lT4bt26YcSIERg2bBhWr17NJKiScWo8ERFR6TRaJ+jmzZvo379/iWsB2draYsCAAbh582aFgyPt4V5hREREyjRKgqysrJCZmVnq8czMTKUVpanycWo8ERGRMo2SIB8fH2zZsgWXLl1SOfbXX38hJiYGvr6+FQ6OiIiISFc0GhP0ySefYMiQIRg2bBi8vb3RqFEjAMA///yDK1euoGbNmpgxY4ZWAyUiIiLSJo1agho2bIj9+/dj5MiRyMzMRFxcHOLi4pCZmYlRo0Zh3759cHV11XasRERERFpT7pYgqVSKjIwMODg4YM6cOZgzZ44u4iIiIiLSKbVbggRBwIoVK9CuXTv4+/vjrbfeQnh4OJ4/f67D8IiIiIh0Q+2WoJ9//hnff/896tati7fffhv379/H8ePHIZPJsGbNGl3GSERERKR1aidBsbGxaNasGbZt26bYMX7RokXYtm0bMjIy4OzsrLMgiYiIiLRN7e6w+/fvo1+/fooECACGDRsGmUyGu3fvai2gpKQkjB07Fq1bt4afnx+WLVsGiURSrntER0dDLBYjLCxMa3ERERFR1aJ2S1BmZqZKa0+NGjUAAAUFBVoJJjMzE6NHj4a7uzsiIyORlpaGpUuXIj8/H3PnzlXrHk+ePMHq1atRs2ZNrcREREREVVO5ZofpesXh7du348WLF4iKioKTkxOA4tloCxYsQFhYGOrUqfPae3z99dcICAhAamqqTmMlIiIi41auJGj58uVYt26d4rVMJgMAfP7557CxsVE6VyQSYf/+/eUK5tSpU/D19VUkQAAQGBiIefPm4cyZMxg4cGCZ158/fx7Hjh1DQkICpk+fXq73JiIiItOidhLUrl27Esu1OSA6OTkZgwYNUipzcHCAi4sLkpOTy7xWKpVi4cKFmDRpEmrXrq2VeARBQG5urlbu9bK8vDylv3UlXyJV/Ds3Lw8yqWntIK+vejZ1rGf9YD3rB+tZP3RZz4IgqN1zpXYSFBMTo3FA6srKyoKDg4NKuaOjY5kbtgLAtm3bkJeXhzFjxmgtnsLCQly/fl1r93tVSkqKzu4NAJIimeLfN2/egGU1jRYIN3q6rmcqxnrWD9azfrCe9UNX9WxpaanWeRrtHWZo0tPTERERga+++krtB1eHhYUFGjdurLX7yeXl5SElJQXu7u4q3YjaVNwSVDw2SixuAmtL02sJ0kc9mzrWs36wnvWD9awfuqznO3fuqH2uQSVBDg4OyM7OVinPzMyEo6NjqdetWrUKYrEYbdu2RVZWFgCgqKgIRUVFyMrKgq2tLapVK/+jikQi2Nralvs6ddnY2Oj0/mbmRYp/29rYwNrKoL7ceqPreqZirGf9YD3rB+tZP3RRz+WZxGVQn4oeHh4qY3+ys7Px5MkTeHh4lHrdP//8g3PnzpU4bqldu3ZYv349/P39tR4vERERGS+DSoL8/f2xdu1apbFBCQkJMDMzg5+fX6nXzZkzR9ECJLdkyRJYW1tj2rRpEIvFOo2biIiIjI9BJUFDhgxBTEwMwsPDERYWhrS0NCxbtgxDhgxRWiNo9OjRSE1NxdGjRwEATZs2VbmXg4MDbG1t4ePjo7f4iYiIyHgY1HQhR0dHbN68Gebm5ggPD8fy5csREhKCWbNmKZ0nk8kglUpLuQsRERHR61WoJSgtLQ3nzp1Deno6evXqhbp160IqlSI7OxvVq1eHuXn5ZyN5enoiOjq6zHPUma6vjyn9REREZLw0SoIEQcDSpUuxdetWFBUVQSQSwcvLC3Xr1kVubi4CAgIwefJkra7ZQ0RERKRNGnWHbdiwAVu2bMG4ceOwadMmCIKgOFa9enX07NkTR44c0VqQRERERNqmURK0a9cu9O/fH9OmTUOTJk1UjovFYq62SURERAZNoyTo0aNHePPNN0s9bmNjg5ycHI2DIiIiItI1jZKgmjVr4tGjR6Uev3btGurVq6dxUERERES6plES1KNHD2zfvh33799XlMmXqT59+jT27NmD3r17aydCIiIiIh3QaHbY5MmTcfbsWfTr1w9t27aFSCTC+vXrsWrVKly+fBlNmzbFpEmTtB0rERERkdZo1BJUvXp17Ny5ExMmTEBaWhqsrKxw7tw5ZGdnIzw8HNu2bePuu0RERGTQNF4s0draGh988AE++OADbcZDWiIIAvIlXFWbiIioNAa1dxhphyAImBl1GtdTMio7FCIiIoOlURI0e/bs154jEomwZMkSTW5PFVQgkSolQE3dnWFlWf4tTIiIiKoyjZKgs2fPqpTJZDI8efIEUqkUzs7OHBNUSV7tBouZ3xuO9paK2XtERERUTKMk6MSJEyWWFxYWYseOHdi8eTM2btxYocCo/ErqBrO2NGcCREREVAKNZoeVxsLCAiNGjICfnx8WLlyozVuTGtgNRkREpD6dDIxu0qQJ9u3bp4tbk5rYDUZERFQ2rbYEySUmJnJMUCVjNxgREVHZNGoJioqKKrE8Ozsb586dw99//42JEydWKDAiIiIiXdJqEuTo6IiGDRtiwYIFCA0NrVBgRERERLqkURJ048YNbcdBFcQVoomIiMqn3ElQfn4+Vq5cCR8fHwQEBOgiJionrhBNRERUfuUeGG1tbY0dO3YgPT1dF/GQBjg1noiIqPw06g5r3rw5bt26pe1YSAs4NZ6IiEg9Gk2RnzNnDuLi4rBr1y4UFRVpOyaqAE6NJyIiUo/aLUHnzp2Dp6cnnJ2dMWvWLIhEIsydOxeLFi1CnTp1YGVlpXS+SCTC/v37tR4wERERkTaonQSNGjUKX3/9Nfr06QMnJyc4OTmhUaNGuoyNiIiISGfUToIEQYAgCACAmJgYnQVEREREpA862TaDiIiIyNCVKwnigFsiIiKqKso1Rf6TTz7BJ598ota5IpEIf//9t0ZBkXoEQUCBRMqVoomIiDRQriSoY8eOcHd311EoVB5cJZqIiKhiypUE9e/fH++8846uYqFyeHWVaIArRRMREZWHRitGk2GJmd8b1pbmsOJCiURERGpjElQFWFuaw9qKX0oiIqLy4BR5IyQIAgdDExERVZDazQc3btzQZRykJg6IJiIi0g62BBmZVwdEczA0ERGRZjiQxIi82g0WM783HO0tORiaiIhIA0yCjERJ3WDWnA1GRESkMXaHGQl2gxEREWkXW4KMELvBiIiIKo4tQUaI3WBEREQVxySIiIiITBKTICIiIjJJTIKIiIjIJDEJIiIiIpPEJIiIiIhMEpMgIiIiMklMgoiIiMgkMQkiIiIik8QkiIiIiEwSkyAiIiIySUyCiIiIyCQxCSIiIiKTxCSIiIiITFK1yg7gVUlJSVi0aBEuXboEOzs79OvXD1OmTIGlpWWp1zx+/BjR0dE4c+YM7t27h+rVq6Ndu3aYNm0aGjRooMfoiYiIyFgYVBKUmZmJ0aNHw93dHZGRkUhLS8PSpUuRn5+PuXPnlnrdtWvXcPToUQwaNAitWrXCs2fPsGbNGrz77rs4ePAgnJ2d9fgUREREZAwMKgnavn07Xrx4gaioKDg5OQEApFIpFixYgLCwMNSpU6fE69566y3Ex8ejWrX/PU6bNm3QpUsX7N27F+PGjdNH+ERERGREDGpM0KlTp+Dr66tIgAAgMDAQMpkMZ86cKfU6BwcHpQQIAOrWrQtnZ2c8fvxYV+ESERGRETOolqDk5GQMGjRIqczBwQEuLi5ITk4u173++ecfpKenw9PTU+N4BEFAbm6uxteXJi8vT+lvdeRLpIp/5+blQSY113pcVY0m9Uzlx3rWD9azfrCe9UOX9SwIAkQikVrnGlQSlJWVBQcHB5VyR0dHZGZmqn0fQRCwaNEi1K5dG8HBwRrHU1hYiOvXr2t8/eukpKSofa6kSKb4982bN2BZzaAa8QxaeeqZNMd61g/Ws36wnvVDV/Vc1mSqlxlUEqQtkZGR+OOPP7BhwwbY2tpqfB8LCws0btxYi5EVy8vLQ0pKCtzd3WFjY6PWNcUtQakAALG4Cawt2RL0OprUM5Uf61k/WM/6wXrWD13W8507d9Q+16CSIAcHB2RnZ6uUZ2ZmwtHRUa177Ny5E6tXr8bixYvh6+tboXhEIlGFkqjXsbGxUfv+ZuZFin/b2tjA2sqgvnQGrTz1TJpjPesH61k/WM/6oYt6VrcrDDCwgdEeHh4qY3+ys7Px5MkTeHh4vPb6o0ePYv78+Zg8eTJCQkJ0FSYRERFVAQaVBPn7+yMxMRFZWVmKsoSEBJiZmcHPz6/Ma8+ePYtp06bh3XffRXh4uK5DJSIiIiNnUEnQkCFDYGdnh/DwcJw+fRq7d+/GsmXLMGTIEKU1gkaPHo0ePXooXiclJSE8PBzu7u7o168fLl++rPhz7969yngUrRIEQWl2GBEREVWcQQ0scXR0xObNm7Fw4UKEh4fDzs4OISEhmDp1qtJ5MpkMUun/koK//voL2dnZyM7OxtChQ5XOHTBgAJYuXaqX+HVBEATMjDqN6ykZlR0KERFRlWJQSRAAeHp6Ijo6usxzYmJilF4PHDgQAwcO1GFUladAIlVKgJq6O8OKM8OIiIgqzOCSIPqfV7vBYub3hqO9ZblGvhMREVHJmAQZqJK6wawtzZkAERERaYlBDYym/2E3GBERkW6xJcgIsBuMiIhI+9gSZATYDUZERKR9TIKIiIjIJDEJIiIiIpPEJIiIiIhMEpMgIiIiMklMgoiIiMgkMQkiIiIik8QkiIiIiEwSkyAiIiIySUyCDNCrG6cSERGR9nHbDANT0sapREREpH1sCTIw3DiViIhIP9gSZMC4cSoREZHusCXIgHHjVCIiIt1hEmRAOCCaiIhIf9gdZiA4IJqIiEi/2BJkIDggmoiISL/YEmSAOCCaiIhI99gSZIA4IJqIiEj3mAQZAA6IJiIi0j92h1UyDogmIiKqHGwJqmQcEE1ERFQ52BJkQDggmoiISH/YEmRAOCCaiIhIf5gEERERkUliEkREREQmiUkQERERmSQmQURERGSSmAQRERGRSWISRERERCaJSVAl4nYZRERElYeLJVYSQRAwd8M53LqXWdmhEBERmSS2BFWSQqmglABxuwwiIiL9YkuQAeB2GURERPrHliADwO0yiIiI9I9JEBEREZkkdocRkcmSSqUoLCys7DDUUlBQoPjbzIy/v+oK61k/NK1nCwsLmJtrb/wsk6BKIAgCJEVCZYdBZLIEQcC///6L58+fV3YoapPJZKhWrRpSU1P54axDrGf9qEg9Ozk5oW7duloZRsIkSM84NZ6o8skToNq1a8PW1tYoxuRJpVIUFBTAyspKq78JkzLWs35oUs+CICA3NxePHz8GANSrV6/CcTAJ0rMCiZRT44kqkVQqVSRANWvWrOxw1CaVFi+sam1tzQ9nHWI964em9WxjYwMAePz4MWrXrl3hrxGToEr0/czOqOviaBS/hRJVFfIxQLa2tpUcCRFpQv5/t7CwsMJJEDs8K5EVp8YTVRr+3yMyTtr8v8skiIiIiEwSkyAiIiIySUyCiIiIyCQxCSIiMlKRkZEQi8WKPz4+Phg6dChOnjxZ4vmZmZn46quv0L17d7Ro0QIdO3bEtGnTkJSUVOL5L168QFRUFPr06YNWrVqhdevWCAkJwaZNmxSL3VVlISEh2Lp1q0p5YWEhfHx80KRJE6Smpqoc//nnnyEWi5GRkaFy7NixYxCLxXjw4IFSeUZGBpYuXYpevXqhZcuWaNOmDUaMGIFdu3YpZlLp2q5duxTv37dvX/zyyy9qXXf+/HmMHDkS7dq1g4+PDyZMmIDr168rnSMIAtavX4+AgAC0aNECffv2xeHDh5XOefDgAVq3bq1SN7rE2WFEREbM2toamzdvBlA8bXjt2rWYNGkStm7dijZt2ijOe/LkCUaMGIHMzExMmjQJzZo1w7///ouNGzciJCQE33//Pdq1a6c4PyMjA6NHj8ajR48wevRovPXWWwCAS5cu4fvvv4eZmRlGjx6t34fVo2PHjuHhw4cYNGiQyrHTp08rFto8ePAgJk6cWKH3unv3LkaNGgWpVIqxY8eiefPmkEgk+OOPP/Dll1+iRo0a6N69e4Xe43UOHTqE//f//h8mTZqEDh06IC4uDh9++CG2bt2K1q1bl3pdcnIyxo8fjw4dOmD58uWQSCRYt24dxowZg4MHD8LFxQUAsGHDBnz77bd4//330bp1axw/fhxz5syBg4OD4tlcXV3Rq1cvREZG4quvvtLp88oxCSIiMmJmZmZKH1KtWrVC586dsXfvXqUkaMGCBUhNTcXevXvh6empKO/evTtCQkIwffp0HD16FFZWVorz79+/j507d8LLy0txfseOHTF8+HAkJyfr/uFKkJ+fD2tra52/z5YtWxAcHFziex08eBAODg5o2LAhDhw4UOEkaMaMGZBKpdi9ezfq1KmjKPf398eIESOQnZ1dofurIyIiAsHBwZgyZQoAoEOHDrh16xZWr16N9evXl3rdsWPHIAgCVq1apagrsViM7t2748yZM+jfvz8kEgnWrFmDkSNH4sMPPwQA+Pr64v79+4iIiFBK8EJCQjB27FjMnDkTzs7Ounvg/8PuMCIiFDfX5xcUVdofQdDOVjp16tSBs7OzUjfNw4cPcezYMfTv318pAQKK11yZNGkS0tLSEB8frzj/8OHDGDJkiFICJOfk5KSUYJUkKSkJH374Idq3b49WrVqhb9++OHjwIIDibg+xWIyEhASlaxYvXoyAgADFa3m30qVLlzB27Fi0bt0ay5Ytw8iRIxEWFqbynj/++CO8vb0VSYMgCPjhhx/Qq1cvtGjRAt26dUN0dHSZccuf/8KFC+jdu7fKsdzcXJw4cQK9evXCwIEDcevWLdy8efO19yzN+fPnceXKFYSFhSklQHL169eHWCzW+P7quH//PlJSUhAYGKhUHhQUhN9//x0SiaTUawsLC2FpaalIngGgevXqKvd/8eIF/Pz8lMp9fX1x8+ZNpe/Vt956C05OTjhw4EBFHkltbAkiIpMnCAJmRp3G9RTVMRz60tTdGV992KnCa6C8ePECmZmZcHV1VZSdO3cOgiCga9euJV4jTzzOnz+P/v374/z58xAEAW+//bZGMaSkpGDw4MGoV68ePvvsM7i4uODWrVsljp9Rx/Tp0zF48GCEhYXBxsYG169fx6JFi/D8+XM4OTkpzjt48CA6d+6s+BBevHgxdu3ahUmTJqFVq1a4ePEivvnmG1hZWWHo0KGlvt+ff/4Jc3NzeHt7qxw7duwYcnNz0adPH/znP//Bl19+iYMHD2qcqPz5558AoHFdC4Kg1pihatVK/7iXt+o1atRIqdzT0xOFhYW4f/++SvIsFxwcrOjqGjNmDCQSCVasWIF69eqhW7duAP63WaqlpaXStfLXSUlJqF+/PoDils1WrVohMTFRL92tBpcEJSUlYdGiRbh06RLs7OzQr18/TJkyRaXyXiUfdLVt2zZkZGSgadOmmD17dpl9mUREVUFRURGA4jFBX3/9Nezs7DBq1CjFcfleS/IPmlfZ29vDwcEB//77LwAgLS0NgOZ7M0VGRsLCwgKxsbGwt7cHUNyNpqkhQ4YodTm5ublh0aJFOHLkCEJDQwEUt95cvnwZ3377LQDg3r17+PHHH7FgwQIMHjxYEUN+fj5Wr16NwYMHl7px57Vr1+Du7l7i587BgwdRp04dtG/fHmZmZujQoQMOHjyIadOmaZTAyuu6tK/N6+zZswezZ89+7XnHjx9XSoxflplZvJWTg4ODUrn8tfx4Sdzd3REdHY0PPvgAa9euBQA0aNAAmzZtUiSjbm5uEIlEuHLlCnx8fBTXXr16tcT7N2nSpMQB6bpgUElQZmYmRo8eDXd3d0RGRiItLQ1Lly5Ffn4+5s6dW+a169evR0REBGbMmAGxWIytW7di3Lhx2LdvHxo2bKinJyAiYyQSifDVh51QINHPLJySaLqCfG5uLpo3b654bW5uju+++w4eHh4VjknTVqk//vgDvXr1UiRAFdWlSxel1zVq1EDHjh1x6NAhRRIUFxcHW1tbRWtXYmIiAKBnz56KJBEoToTWr1+PR48eoUGDBiW+39OnT0scj5KRkYEzZ85g5MiRigTqnXfewcyZM3HhwgW0bdu2ws9aXl27dsVPP/302vNq166tk/f/559/8NFHH8HPzw/9+/dHQUEBNm7ciPfeew/bt29HrVq1YG9vj759+2LDhg3w8vJSDIyWzw579fusRo0aePbsGQoLC2FhYaGTuOUMKgnavn27YkqmvIlTKpViwYIFpfaXAsVNbevWrcO4ceMwZswYAMX9ir1798YPP/yA+fPn6+cBiMhoiUQiWFsZ1I9EtVhbW+PHH3+EIAhISUnB8uXLMXPmTBw4cEDxwSf/OzU1FU2aNFG5R05ODrKyslC3bl0AUPysffTokUoXiTrkG9RqS61atVTKgoODMWvWLDx58gQuLi44dOgQevTooRib8uzZMwiCgA4dOpR4z7KSIIlEUmIrUHx8PIqKitC5c2dkZWUBAHx8fGBpaYkDBw4okiD5flYymUzlHvKuK/mH+8t1/cYbb5ReCaVwcnJSGYNTkrK6wxwdHQEA2dnZitlcABTPKD9ekpUrV6JWrVpYtmyZoqx9+/bo2rUrtmzZgmnTpgEAZs+ejadPnypa9GrUqIH3338fK1euVHpP4H/dZAUFBaaVBJ06dQq+vr5KfbyBgYGYN28ezpw5g4EDB5Z43cWLF5GTk6M0qMvS0hI9evTA0aNHdR02EVGlMTMzQ8uWLQEA3t7eaNSoEUJDQ7F69WosWLAAANCuXTuIRCL8+uuvSgOP5X799VcAUHyIy8//7bffNOrGcnJyUnTBlUSeqMg3s5WTf+iqo1u3brC0tER8fDw6deqE69evKz5wgeIPbpFIhG3btpX4QVpWcvdy1+DL5AO75b9svywhIQGff/45LCwsFK1IT58+VUngHj9+DDMzM8XnXPv27QEUT7vXJAnSRneYvNUwOTlZqQUxOTkZFhYWZfam3LlzR2XYiZ2dHdzc3HDv3j1FWY0aNbBx40akpaUhMzMTDRs2xOHDh2FhYYFmzZopXZ+VlQULCwuttSSWxaCSoOTkZJU1GRwcHODi4lLmdEz5sVebfz09PbF582aNp1QKgoDc3NxyX1eW/Jea2/Pz8pBrWbEdcKl0eXl5Sn+TbhhbPRcUFEAmk0EqleptETptkM8ee3kgrEwmUxkY26xZMwQFBeHnn3/G+++/DxcXF9StWxfdunXD3r17FUMO5PLy8rBmzRrUrVsXPXv2hFQqRZ06ddCzZ0/Exsaif//+aNy4sVIsWVlZSE5OLnXMZYcOHXD48GFMmzYNdnZ2KsednJxQrVo13LlzRxG7RCJRDBJ++fnkf7/6tbKxsUHnzp1x8OBBPHv2DM7OzvDx8VGcJx97kpGRUeqA8JK+/oIg4I033sCFCxeUjj98+BCXLl3C4MGDVWZR3bhxA0uXLsXJkyfRtWtXtGjRApaWljh69Cj+85//KJ179OhRtGzZEtWqVYNUKsWbb76Jli1bYu3atejWrZtKq8ijR4+QnZ1d4iw9AOjcuTN27txZ4rGX1axZs9Tv9/r168Pd3R3x8fFKdRUXF4cOHTrA3Ny81Gvr1auHv//+G0VFRYpurZycHNy9exft27dXua5WrVqoVasWioqKsGvXLgQGBsLGxkbpvAcPHsDd3b3U95RKpZDJZMjLyyuxtU0QBLW7cg0qCcrKylIZmAUUZ/RlDczKyspSmaIHFCdQgiAgMzNToySosLBQZdXLihIEAQ1dipv6Uh/ew6NU7mStaykpKZUdgkkwpnquVq2a0a54/HLc8rEu+fn5SueMGzcO8fHx2LRpEyZPngwA+PTTT3Hr1i2MGDEC48aNg1gsxpMnT7BlyxY8fPgQERERxcsE/N+9Pv30U9y5cwfDhw/H8OHD0apVKwDAf//7X+zYsQNjxowpsWsNACZMmIBff/0Vw4YNw+jRo1GrVi0kJycjPz9f0YoSEBCArVu3ol69enBycsKOHTsgk8kgEokUMchbivLz81WeEQB69OiBGTNm4OHDh+jWrRuKiooUdVK3bl2EhoZi5syZGDVqFFq2bImioiLcvXsX58+fx4oVK0qt49atW2P9+vW4e/euortq3759AIDhw4ertKg0a9YM33//Pfbv3w9fX19YWlpixIgRWLNmDbKystCuXTsUFBTg0KFDOHfuHCIiIpSeZ+HChZg4cSJCQkIwYsQING3aFBKJBBcuXMCuXbvwxRdfwM3NrcRYra2tVZLUkshkshLrUG7ixIn47LPPUK9ePbRr1w5HjhzBlStXsH79esV1qamp6NevH9577z1Ft9bAgQMxbdo0TJ8+HcHBwZBIJIiJiYFEIsE777yjuDYuLg4FBQVo2LAhnjx5gt27dyM1NRWLFy9Wievq1ato3bp1qfEWFBSgqKiozMaR102mkjOoJMjQWFhYqPXNVV5fuOciJSUFjRo1go2NjdbvT8Xy8vKQkpICd3d31rMOGVs9FxQUIDU1FVZWVnpZdE9bBEFAQUEBrKysFL/lysd5vPocTZo0QWBgIH766Se8//77qF69OlxdXbFjxw58//332L59O/799184ODjAx8cHX3/9tcoU6Hr16mH79u2Ijo5GQkICNm3aBDMzMzRu3BgTJkzA4MGDVX7xlPPy8sK2bduwcuVKLF26FFKpFG+88Qbee+89Raxz587FvHnzFLPZxo0bB09PTxw/flxxjrwby9rausSvVffu3VG9enU8ffoUffv2VTln7ty5aNy4MXbu3In169fD1tYWjRo1Qq9evUr92guCgLZt28LJyQl//vkn3n33XQDA4cOH8eabb5b6mdCnTx/FFhd2dnaYPn066tWrh507d2L79u0wNzdH8+bNsW7dOpX1cry8vLB7925s2LABP/30E/79919YWlqiadOmmDVrFnr06KEYZ6Qr/fv3h1Qqxfr16xEdHY1GjRohIiJCaTaXlZUVpFIpzMzMFPUnX0tp06ZNmD17NiwsLNC0aVNs2rRJqfWqWrVq2LhxIx48eABbW1v4+/tj8eLFcHV1VWq1SU9PV3RtlvX/s1q1anBzcyvxe/DOnTtqP7dI0NYKXVrg6+urWLn0ZW+//Tb69euHGTNmlHjd1q1b8cUXX+DKlStKFbJz507MnTsXly9fLvcPO/nUPXlfuzbl5ubi+vXraNq0KWxtbbV+fyrGetYPY6vn/Px8/PPPP2jUqJFRJUFSqVTRta/rD0RTJq/nVatW4caNG9iyZUtlh1Qllfb9vHXrVkRHR+PIkSOldmm97v9weT6/DWrFaA8PD5XmrezsbDx58qTM6Z7yY//8849SeXJyMurXr29UP+iIiKjyjRs3DleuXMGNGzcqOxSTIZPJsGXLFoSHh1d40VB1GVQS5O/vj8TERKUZAgkJCTAzM1NpPnxZmzZtYG9vr1jyHSjuSz5y5Aj8/f11GjMREVU9Li4u+PLLL0vcCZ504/HjxxgwYAD69u2rt/c0qDFBQ4YMQUxMDMLDwxEWFoa0tDQsW7YMQ4YMUVojaPTo0UhNTVVMf7eyskJYWBgiIyPh7OwMLy8vxMbG4vnz5xg/fnxlPQ4RERmxV2eBkW7VrVsXkyZN0ut7GlQS5OjoiM2bN2PhwoUIDw+HnZ0dQkJCMHXqVKXzSpou+d5770EQBGzcuFGxbcYPP/zA1aKJiIioRAaVBAHFa/u8bpffmJgYlTKRSISwsLASdxYmInqVAc0JIaJy0Ob/XYMaE0REpGvyadfaXgiViPRD/n9XG1tqGFxLEBGRLpmbmytt62Bra6u3mSgVIZVKFQslcoq87rCe9UOTepbv4vD48WM4OTlp5evDJIiITI58o9Cy9rcyNDKZDEVFRahWrZpiB3PSPtazflSknp2cnBT/hyuKSRARmRyRSIR69eqhdu3aKpt4Gqq8vDwkJyfDzc3NKFbmNlasZ/3QtJ4tLCy02kLHJIiITJa5ubnRdHnIN4o0tu0+jA3rWT8MpZ7Z1kdEREQmiUkQERERmSQmQURERGSSDGoXeUNy8eJFCIIAS0tLrd9bEAQUFhbCwsLCKKbmGivWs36wnvWD9awfrGf90GU9SyQSiEQitGnT5rXncmB0KXT5zS8SiXSSXJEy1rN+sJ71g/WsH6xn/dBlPYtEIrU/w9kSRERERCaJY4KIiIjIJDEJIiIiIpPEJIiIiIhMEpMgIiIiMklMgoiIiMgkMQkiIiIik8QkiIiIiEwSkyAiIiIySUyCiIiIyCQxCSIiIiKTxCSIiIiITBKTICIiIjJJTIK0KCkpCWPHjkXr1q3h5+eHZcuWQSKRvPY6QRDw/fffo0uXLvD29sbgwYNx+fJl3QdsxDSp68ePH2PZsmXo168f3nzzTfj7+2P69Ol4+PChnqI2Ppp+T78sOjoaYrEYYWFhOorS+FWkntPS0jBz5kx06NAB3t7eCAwMxP79+3UcsXHStJ6fPXuGuXPnokuXLmjdujX69OmD2NhYPURsnO7evYu5c+eiX79+aNasGfr06aPWdZXxWVhNp3c3IZmZmRg9ejTc3d0RGRmJtLQ0LF26FPn5+Zg7d26Z165fvx4RERGYMWMGxGIxtm7dinHjxmHfvn1o2LChnp7AeGha19euXcPRo0cxaNAgtGrVCs+ePcOaNWvw7rvv4uDBg3B2dtbjUxi+inxPyz158gSrV69GzZo1dRyt8apIPT9+/BiDBw9Go0aNsHDhQtjb2+P27dvlTlRNQUXq+eOPP0ZycjKmTZuGevXq4dSpU5g/fz7Mzc0RGhqqpycwHrdv38bJkyfRqlUryGQyCIKg1nWV8lkokFasXbtWaN26tfDs2TNF2fbt24WmTZsK//77b6nX5efnC23atBGWL1+uKCsoKBC6du0qzJs3T4cRGy9N6zozM1MoLCxUKnv06JEgFouFH374QVfhGi1N6/lln3zyifDpp58KI0aMECZOnKijSI1bRep5xowZwuDBg4WioiIdR2n8NK3nx48fC15eXsLu3buVyocPHy6MGjVKV+EaNalUqvj3zJkzheDg4NdeU1mfhewO05JTp07B19cXTk5OirLAwEDIZDKcOXOm1OsuXryInJwcBAYGKsosLS3Ro0cPnDp1SpchGy1N69rBwQHVqik3ftatWxfOzs54/PixrsI1WprWs9z58+dx7NgxTJ8+XYdRGj9N6zknJwfx8fEYNmwYzM3N9RCpcdO0nouKigAA1atXVyq3t7dXu4XD1JiZlT+1qKzPQiZBWpKcnAwPDw+lMgcHB7i4uCA5ObnM6wCoXOvp6YnU1FTk5+drP1gjp2ldl+Sff/5Beno6PD09tRlilVCRepZKpVi4cCEmTZqE2rVr6zJMo6dpPV+7dg2FhYWoVq0aRowYgebNm8PPzw9ff/01CgsLdR220dG0nuvVq4dOnTph7dq1uHPnDnJychAXF4czZ85g+PDhug7bZFTWZyHHBGlJVlYWHBwcVModHR2RmZlZ5nWWlpawsrJSKndwcIAgCMjMzIS1tbXW4zVmmtb1qwRBwKJFi1C7dm0EBwdrM8QqoSL1vG3bNuTl5WHMmDE6iq7q0LSenz59CgD4/PPPERoaig8//BBXrlxBREQEzMzM2AL3iop8P0dGRmLq1KmKnxPm5ub4/PPP0atXL53Eaooq67OQSRCZrMjISPzxxx/YsGEDbG1tKzucKiM9PR0RERH46quvYGlpWdnhVFkymQwA0LFjR8yaNQsA0KFDB7x48QIbN25EeHg4f4HSAkEQMHv2bKSkpGD58uVwcXFBYmIilixZAkdHR/4CZeSYBGmJg4MDsrOzVcozMzPh6OhY5nUSiQQFBQVKGXBWVhZEIlGZ15oqTev6ZTt37sTq1auxePFi+Pr6ajvEKkHTel61ahXEYjHatm2LrKwsAMXjKoqKipCVlQVbW1uVsVmmrCI/O4DixOdlvr6+WLt2Le7evQuxWKzdYI2YpvX866+/IiEhAfv371fUp4+PD9LT07F06VImQVpSWZ+FHBOkJR4eHir9ytnZ2Xjy5IlKH+er1wHFY1NelpycjPr16/M3uRJoWtdyR48exfz58zF58mSEhIToKkyjp2k9//PPPzh37hzatWun+HPx4kWcPn0a7dq1Q2Jioq5DNyqa1nPjxo3LvG9BQYFW4qsqNK3nO3fuwNzcHF5eXkrlTZs2xePHj5GXl6eTeE1NZX0WMgnSEn9/fyQmJip+8wWAhIQEmJmZwc/Pr9Tr2rRpA3t7e8THxyvKCgsLceTIEfj7++s0ZmOlaV0DwNmzZzFt2jS8++67CA8P13WoRk3Tep4zZw62bNmi9KdJkyZo3bo1tmzZAm9vb32EbzQ0recGDRrAy8tLJalMTEyEtbX1a5MkU1ORepZKpbh586ZS+bVr11CzZk3Y2NjoLGZTUmmfhTqbfG9inj9/Lvj5+QkjRowQfvvtN+Gnn34S2rZtKyxYsEDpvFGjRgndu3dXKlu3bp3QokULITo6WkhMTBQ++ugj4c033xTu3bunz0cwGprW9Z07d4S33npL6NOnj3DhwgXh0qVLij93797V92MYvIp8T7+K6wSVriL1fPz4cUEsFguLFi0STp8+LaxZs0Zo3ry5sGLFCn0+glHQtJ6zs7OFLl26CD169BD27t0rJCYmCsuWLROaNGkirF69Wt+PYRRyc3OF+Ph4IT4+XhgxYoTQuXNnxev09HRBEAzns5Ad81ri6OiIzZs3Y+HChQgPD4ednR1CQkIwdepUpfNkMhmkUqlS2XvvvQdBELBx40ZkZGSgadOm+OGHH7hadCk0reu//voL2dnZyM7OxtChQ5XOHTBgAJYuXaqX+I1FRb6nSX0VqeeAgACsWLEC3333HWJjY1G7dm189NFHmDhxoj4fwShoWs/29vaIjo7GypUr8c033yA7Oxuurq6YNWsWRowYoe/HMArp6en4+OOPlcrkr7ds2QIfHx+D+SwUCQJXeyIiIiLTwzFBREREZJKYBBEREZFJYhJEREREJolJEBEREZkkJkFERERkkpgEERERkUliEkREREQmiUkQERERmSQmQUSk5OzZsxCLxTh79mxlh6JTYrEYkZGRap0bEBCAWbNm6TgiItI3bptBVEX8/PPPmD17donH3nvvPcyYMUPPEanv1dgtLS1Rv359+Pn54YMPPkCtWrV0HsPFixdx5swZjB49Gg4ODjp/P3UEBATg4cOHitc2NjZo3LgxRowYgf79+2t0z5MnT+LKlSv46KOPtBQlkfFiEkRUxUyePBmurq5KZV5eXpUUTfnIY5dIJLhw4QJiY2Nx8uRJHDx4UOu7dV+5cgXm5uaK15cuXUJUVBQGDBigkgQlJCRAJBJp9f3V1bRpU4wdOxYA8OTJE+zatQszZ86ERCJBaGhoue938uRJbN26lUkQEZgEEVU5/v7+aNmyZWWHoZGXY3/33Xfh5OSETZs24fjx4+jTp49W38vKykrtcy0tLbX63uVRp04d9OvXT/F64MCB6NatG6KjozVKgojofzgmiMhEPHz4EPPnz0evXr3g7e0NHx8fTJ48GQ8ePHjttSkpKfjoo4/g5+eHli1bwt/fH1OnTkV2drbSefv27cPAgQPh7e2N9u3bY+rUqXj06JHGMXfo0AEAFDEWFRVh9erV6N69O1q0aKHYRV0ikShdd/XqVYwfPx4+Pj7w9vZGQECASlfhy2OCIiMjsWzZMgBAt27dIBaLIRaLFe/78pigq1evQiwWY8+ePSrx/vbbbxCLxfjll18UZWlpaZg9ezY6duyIFi1aIDg4GD/99JPGdeLs7AwPDw/cu3dPqfz8+fOYPHkyunTpghYtWqBz585YsmQJ8vPzFefMmjULW7duVTy//I+cTCZDdHQ0goOD0bJlS3Ts2BFz585FZmamxvESGTK2BBFVMTk5OcjIyFAqc3Z2xtWrV3Hp0iUEBwejbt26ePjwIWJjYzFq1CgcOnSo1O4miUSC8ePHQyKRYMSIEahVqxbS0tLw66+/IisrC9WrVwcArFmzBqtWrUJgYCBCQkKQkZGBH3/8EcOHD8fevXs1Gmcj/6B3cnICAHz++efYs2cPevXqhbFjx+LKlStYt24dkpKSsHr1agBAeno6xo8fjxo1amDixIlwcHDAgwcPcPTo0VLfp0ePHkhJScHBgwcxe/Zs1KhRQ1Fvr2rZsiUaNmyI+Ph4DBgwQOlYXFwcHB0d0alTJwDA06dPERoaCpFIhOHDh8PZ2RmnTp3CZ599hpycHIwZM6bcdVJUVIS0tDQ4OjoqlSckJCA/Px9Dhw6Fk5MTrly5gh9//BH//vsvIiIiAACDBw/G48ePcebMGUXS97K5c+diz549GDhwIEaOHIkHDx5g69at+PvvvxEbGwsLC4tyx0tk0AQiqhJ2794teHl5lfhHEAQhLy9P5ZpLly4JXl5ewp49exRlf/zxh+Dl5SX88ccfgiAIwt9//y14eXkJ8fHxpb73gwcPhKZNmwpr1qxRKr9586bQrFkzlfLSYk9MTBTS09OFR48eCYcOHRLat28veHt7C//++69w/fp1wcvLS/jss8+Url26dKng5eUl/P7774IgCMLRo0cFLy8v4cqVK2W+p5eXlxAREaF4vWHDBsHLy0u4f/++yrldu3YVZs6cqXi9fPlyoXnz5sLz588VZQUFBULbtm2F2bNnK8rmzJkj+Pn5CRkZGUr3mzp1qvDWW2+V+DV59X3HjRsnpKenC+np6cLNmzeFTz75RPDy8hIWLFigdG5J91q3bp0gFouFhw8fKsoWLFig+J542blz5wQvLy9h//79SuWnTp0qsZyoKmBLEFEVM3fuXDRq1Eil3NraWvHvwsJC5OTkwM3NDQ4ODvj7779LnW1kb28PADh9+jQ6d+5cYovR0aNHIZPJEBgYqNQKVatWLbzxxhs4e/YsJk2a9NrYX20ZadCgAb755hvUqVMHe/fuBQDFIGG5cePGYePGjTh58iQ6dOigaJn69ddf0aRJE520XgQFBWHdunU4cuQI3n33XQDAmTNnkJWVhaCgIACAIAg4cuQIAgMDIQiCUr106tQJhw4dwrVr1/DWW2+V+V6nT5+Gr6+vUtnAgQPx6aefKpW9/PXNzc1Ffn4+3nzzTQiCgL///hv169cv830SEhJQvXp1+Pn5KcXavHlz2Nra4uzZs3jnnXfKvAeRsWESRFTFeHt7lzgwOj8/H+vWrcPPP/+MtLQ0CIKgOPbq2J6XNWzYEGPHjsWmTZtw4MABtG3bFgEBAejbt68i4UhJSYEgCOjZs2eJ96hWTb0fNfIEztzcHLVq1UKjRo1gZlY8dPHhw4cwMzODm5ub0jUuLi5wcHBQTCVv3749evXqhaioKERHR6N9+/bo3r073nnnHa0NcG7SpAk8PDwQHx+vSILi4uJQo0YNxTimjIwMZGVlYceOHdixY0eJ93m127IkrVq1wpQpUyCVSnH79m2sWbMGWVlZKsldamoqIiIicOLECZUxPDk5Oa99n7t37yI7O1sl4ZJLT09/7T2IjA2TICITsXDhQvz8888YPXo0WrdujerVq0MkEmHq1KlKCVFJZs2ahQEDBuD48eM4c+YMFi1ahHXr1mHnzp2oW7cuZDIZRCIR1q9frzTtXM7W1latGEtL4F72uqnqIpEIERERuHz5Mn755Rf89ttvmDNnDjZt2oQdO3bAzs5OrVheJygoCGvXrkVGRgbs7e1x4sQJBAcHKxI+mUwGAOjbt6/K2CG5lwcll6ZGjRro2LEjAODtt9+Gh4cHwsLCsGXLFkWrmFQqxdixY5GZmYkJEybAw8MDtra2SEtLw6xZsxSxlEUmk6FmzZr45ptvSjxe0vgoImPHJIjIRBw+fBj9+/dXWvm4oKCgzFagl8lnEn3wwQe4ePEihg4ditjYWEydOhVubm4QBAGurq4ldsVpQ4MGDSCTyXD37l14enoqyp8+fYqsrCw0aNBA6fzWrVujdevWmDp1Kg4cOIAZM2YgLi5O0XLzqvKuAxQUFISoqCgcOXIEtWrVQk5ODoKDgxXHnZ2dYWdnB5lMpkhitKFLly5o37491q5di8GDB8PW1ha3bt1CSkoKvvrqK6VuzTNnzqhcX9pzurm54ffff0ebNm2UutaIqjJOkScyESW10MTExEAqlZZ5XU5ODoqKipTKvLy8YGZmppia3rNnT5ibmyMqKkqlVUkQBDx79qyC0QOdO3cGAGzevFmpfNOmTUrHMzMzVWJo2rQpAKhMpX+ZfKyTukmhp6cnvLy8EBcXh7i4OLi4uKBdu3aK4+bm5ujVqxcOHz6MW7duqVyvTldYaSZMmIDnz59j586dAKDoMnz5uQVBwJYtW1SulT9nVlaWUnlgYCCkUim+++47lWuKiopUzieqCtgSRGQiunTpgn379sHe3h6NGzfG5cuXkZiYqJh+Xpo//vgDX3zxBXr37g13d3dIpVLs27dP8SEPFLciTJkyBcuXL8fDhw/RvXt32NnZ4cGDBzh27BhCQ0Mxfvz4CsXfpEkTDBgwADt27EBWVhbatWuHq1evYs+ePejevbtiLM6ePXsQGxuL7t27w83NDS9evMDOnTthb28Pf3//Uu/fvHlzAMDKlSsRFBQECwsLdO3atcyuvKCgIERERMDKygohISGKZERu+vTpOHv2LEJDQ/Huu++icePGyMzMxLVr1/D777/jzz//1KguOnfuDC8vL0RHR2P48OHw8PCAm5sbvvrqK6SlpcHe3h6HDx8uMXGRP+eiRYvQqVMnmJubIzg4GO3bt8fgwYOxbt06XL9+HX5+frCwsEBKSgoSEhLw2WefoXfv3hrFS2SomAQRmYjPPvsMZmZmOHDgAAoKCtCmTRts2rQJEyZMKPM6sViMTp064ZdffkFaWhpsbGwgFouxfv16tG7dWnHexIkT4e7ujujoaMWaPXXr1oWfnx8CAgK08gyLFi2Cq6sr9uzZg2PHjqFWrVoICwvDhx9+qDinffv2uHr1KuLi4vD06VNUr14d3t7e+Oabb9CwYcNS7+3t7Y2PP/4Y27dvx2+//QaZTIbjx4+/Ngn69ttvkZeXh8DAQJXjtWrVwq5du7B69WocPXoUsbGxcHJyQuPGjSu8l9u4ceMwa9YsHDhwAAMHDsTatWsVY7WsrKzQo0cPDB8+XGm1aaC41W7kyJE4dOgQ9u/fD0EQFN14X3zxBVq0aIHt27dj5cqVMDc3R4MGDdC3b1+0adOmQvESGSKR8LoRkURERERVEMcEERERkUliEkREREQmiUkQERERmSQmQURERGSSmAQRERGRSWISRERERCaJSRARERGZJCZBREREZJKYBBEREZFJYhJEREREJolJEBEREZkkJkFERERkkv4/udL5NvIbYxgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8853342138780131\n"
     ]
    }
   ],
   "source": [
    "# calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(testY, logreg.predict_proba(testX)[:,1])\n",
    "\n",
    "# Calculate the AUC value\n",
    "auc_value = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label='ROC curve (AUC = {:.2f})'.format(auc_value))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Print the AUC value\n",
    "print('AUC:', auc_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the train and test data\n",
    "x = df_selected.drop(columns=['classification target', 'regression target'])\n",
    "y = df_selected['classification target']\n",
    "trainX, testX, trainY, testY = train_test_split(x, y, test_size=0.2, random_state=4211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step size: 0.01 Accuracy: 0.878060263653484 F1 score: 0.9092248668220959\n",
      "Step size: 0.2 Accuracy: 0.8418079096045198 F1 score: 0.9036922366854705\n",
      "Step size: 0.4 Accuracy: 0.8512241054613936 F1 score: 0.9014629258204784\n",
      "Step size: 0.6 Accuracy: 0.8418079096045198 F1 score: 0.8998967096164808\n",
      "Step size: 0.8 Accuracy: 0.812617702448211 F1 score: 0.8932031436067754\n",
      "Step size: 0.99 Accuracy: 0.8262711864406779 F1 score: 0.8911163937037815\n"
     ]
    }
   ],
   "source": [
    "steps = [0.01, 0.2, 0.4, 0.6, 0.8, 0.99]\n",
    "for step in steps:\n",
    "    tempacc = []\n",
    "    tempf1 = []\n",
    "    logreg = SGDClassifier(loss='log_loss', learning_rate='constant', eta0=step)\n",
    "    for i in range(3):\n",
    "        start = time.time()\n",
    "        logreg.fit(trainX, trainY)\n",
    "        end = time.time()\n",
    "        elapsed_time = end - start\n",
    "        prediction = logreg.predict(testX)\n",
    "        tempacc.append(accuracy_score(testY, prediction))\n",
    "        tempF1.append(f1_score(testY, prediction))\n",
    "    # get the mean accuracy and F1 score\n",
    "    mean_acc = np.mean(tempacc)\n",
    "    mean_f1 = np.mean(tempF1)\n",
    "    print(\"Step size: \" + str(step) + \" Accuracy: \" + str(mean_acc) + \" F1 score: \" + str(mean_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ffnn models for classification with the same hidden layers as the regression models\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(1,1,1), early_stopping=True)\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(8,8,8), early_stopping=True)\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(32,32,32), early_stopping=True)\n",
    "mlp4 = MLPClassifier(hidden_layer_sizes=(128,128,128), early_stopping=True)\n",
    "\n",
    "H = [1, 8, 32, 128]\n",
    "f1scores = []\n",
    "accs = []\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time taken for model 1: 0.12121772766113281\n",
      "Mean Accuracy for model 1: 0.565442561205273\n",
      "Mean F1 score for model 1: 0.5473216763807938\n"
     ]
    }
   ],
   "source": [
    "tempacc = []\n",
    "tempf1 = []\n",
    "temptime = []\n",
    "for i in range(3):\n",
    "    # train model 1 and get its training time\n",
    "    start = time.time()\n",
    "    mlp1.fit(trainX, trainY)\n",
    "    end = time.time()\n",
    "    temptime.append(end - start)\n",
    "    # make predictions\n",
    "    mlp1pred = mlp1.predict(testX)\n",
    "    # get f1 score\n",
    "    mlp1f1 = f1_score(testY, mlp1pred)\n",
    "    tempf1.append(mlp1f1)\n",
    "    # get accuracy\n",
    "    mlp1acc = accuracy_score(testY, mlp1pred)\n",
    "    tempacc.append(mlp1acc)\n",
    "# print time, accuracy and f1 score\n",
    "mean_acc = np.mean(tempacc)\n",
    "mean_f1 = np.mean(tempf1)\n",
    "mean_time = np.mean(temptime)\n",
    "times.append(mean_time)\n",
    "f1scores.append(mean_f1)\n",
    "accs.append(mean_acc)\n",
    "print(\"Mean Time taken for model 1: \" + str(mean_time))\n",
    "print(\"Mean Accuracy for model 1: \" + str(mean_acc))\n",
    "print(\"Mean F1 score for model 1: \" + str(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time taken for model 2: 0.28888432184855145\n",
      "Mean Accuracy for model 2: 0.8747645951035782\n",
      "Mean F1 score for model 2: 0.914299977720345\n"
     ]
    }
   ],
   "source": [
    "tempacc = []\n",
    "tempf1 = []\n",
    "temptime = []\n",
    "for i in range(3):\n",
    "    # train model 2 and get its training time\n",
    "    start = time.time()\n",
    "    mlp2.fit(trainX, trainY)\n",
    "    end = time.time()\n",
    "    temptime.append(end - start)\n",
    "    # make predictions\n",
    "    mlp2pred = mlp2.predict(testX)\n",
    "    # get f1 score\n",
    "    mlp2f1 = f1_score(testY, mlp2pred)\n",
    "    tempf1.append(mlp2f1)\n",
    "    # get accuracy\n",
    "    mlp2acc = accuracy_score(testY, mlp2pred)\n",
    "    tempacc.append(mlp2acc)\n",
    "# print time, accuracy and f1 score\n",
    "mean_acc = np.mean(tempacc)\n",
    "mean_f1 = np.mean(tempf1)\n",
    "mean_time = np.mean(temptime)\n",
    "times.append(mean_time)\n",
    "f1scores.append(mean_f1)\n",
    "accs.append(mean_acc)\n",
    "print(\"Mean Time taken for model 2: \" + str(mean_time))\n",
    "print(\"Mean Accuracy for model 2: \" + str(mean_acc))\n",
    "print(\"Mean F1 score for model 2: \" + str(mean_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time taken for model 3: 0.33731834093729657\n",
      "Mean Accuracy for model 3: 0.8818267419962336\n",
      "Mean F1 score for model 3: 0.9187939836306042\n"
     ]
    }
   ],
   "source": [
    "tempacc = []\n",
    "tempf1 = []\n",
    "temptime = []\n",
    "for i in range(3):\n",
    "    # train model 3 and get its training time\n",
    "    start = time.time()\n",
    "    mlp3.fit(trainX, trainY)\n",
    "    end = time.time()\n",
    "    temptime.append(end - start)\n",
    "    # make predictions\n",
    "    mlp3pred = mlp3.predict(testX)\n",
    "    # get f1 score\n",
    "    mlp3f1 = f1_score(testY, mlp3pred)\n",
    "    tempf1.append(mlp3f1)\n",
    "    # get accuracy\n",
    "    mlp3acc = accuracy_score(testY, mlp3pred)\n",
    "    tempacc.append(mlp3acc)\n",
    "# print time, accuracy and f1 score\n",
    "mean_acc = np.mean(tempacc)\n",
    "mean_f1 = np.mean(tempf1)\n",
    "mean_time = np.mean(temptime)\n",
    "times.append(mean_time)\n",
    "f1scores.append(mean_f1)\n",
    "accs.append(mean_acc)\n",
    "print(\"Mean Time taken for model 3: \" + str(mean_time))\n",
    "print(\"Mean Accuracy for model 3: \" + str(mean_acc))\n",
    "print(\"Mean F1 score for model 3: \" + str(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time taken for model 4: 1.1054277420043945\n",
      "Mean Accuracy for model 4: 0.8738229755178907\n",
      "Mean F1 score for model 4: 0.9129310454454197\n"
     ]
    }
   ],
   "source": [
    "tempacc = []\n",
    "tempf1 = []\n",
    "temptime = []\n",
    "for i in range(3):\n",
    "    # train model 4 and get its training time\n",
    "    start = time.time()\n",
    "    mlp4.fit(trainX, trainY)\n",
    "    end = time.time()\n",
    "    temptime.append(end - start)\n",
    "    # make predictions\n",
    "    mlp4pred = mlp4.predict(testX)\n",
    "    # get f1 score\n",
    "    mlp4f1 = f1_score(testY, mlp4pred)\n",
    "    tempf1.append(mlp4f1)\n",
    "    # get accuracy\n",
    "    mlp4acc = accuracy_score(testY, mlp4pred)\n",
    "    tempacc.append(mlp4acc)\n",
    "# print time, accuracy and f1 score\n",
    "mean_acc = np.mean(tempacc)\n",
    "mean_f1 = np.mean(tempf1)\n",
    "mean_time = np.mean(temptime)\n",
    "times.append(mean_time)\n",
    "f1scores.append(mean_f1)\n",
    "accs.append(mean_acc)\n",
    "print(\"Mean Time taken for model 4: \" + str(mean_time))\n",
    "print(\"Mean Accuracy for model 4: \" + str(mean_acc))\n",
    "print(\"Mean F1 score for model 4: \" + str(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the f1 and accuracy scores to H values\n",
    "plt.plot(H, f1scores, label='F1 Score')\n",
    "plt.plot(H, accs, label='Accuracy')\n",
    "plt.xlabel('Number of hidden units')\n",
    "plt.ylabel('Mean Score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most efficient NN Mean Accuracy: 0.8818267419962336\n",
      "Mean F1 score: 0.9187939836306042\n",
      "Mean Time taken: 0.33731834093729657\n",
      "Logistic Regression Mean Accuracy: 0.8592278719397363\n",
      "Logistic Regression Mean F1 score: 0.9012658432782242\n",
      "Logistic Regression Mean Time taken: 0.03864638010660807\n"
     ]
    }
   ],
   "source": [
    "# print info to compare with lin reg\n",
    "print(\"Most efficient NN Mean Accuracy: \" + str(accs[2]))\n",
    "print(\"Mean F1 score: \" + str(f1scores[2]))\n",
    "print(\"Mean Time taken: \" + str(times[2]))\n",
    "print(\"Logistic Regression Mean Accuracy: \" + str(lr_mean_acc))\n",
    "print(\"Logistic Regression Mean F1 score: \" + str(lr_mean_f1))\n",
    "print(\"Logistic Regression Mean Time taken: \" + str(lr_mean_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for pipeline A: 0.9206963249516441\n",
      "Accuracy for pipeline A: 0.884180790960452\n",
      "F1 score for pipeline B: 0.8956937799043062\n",
      "Accuracy for pipeline B: 0.846045197740113\n",
      "F1 score for pipeline C: 0.9215876089060987\n",
      "Accuracy for pipeline C: 0.885593220338983\n"
     ]
    }
   ],
   "source": [
    "# split into num and cat\n",
    "non_ord_features = cat_features.drop(columns=['C2', 'C5', 'classification target'])\n",
    "non_num = cat_features.drop(columns=['classification target']) \n",
    "class_target = df_train['classification target']\n",
    "\n",
    "# create relevant preprocessors for A, B and C\n",
    "preprocessor_A = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')), ('scaler', StandardScaler())]), num_features.columns),\n",
    "        ('cat', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('encoder', OneHotEncoder())]), non_num.columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_B = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', MinMaxScaler())]), num_features.columns),\n",
    "        ('ord', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('encoder', OrdinalEncoder())]), ord_features.columns),\n",
    "        ('non_ord', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('encoder', OneHotEncoder())]), non_ord_features.columns)\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_C = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('disc', Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', RobustScaler())]), disc_features.columns), \n",
    "        ('cont', Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')), ('scaler', StandardScaler())]), cont_features.columns),\n",
    "        ('ord', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('encoder', OrdinalEncoder())]), ord_features.columns),\n",
    "        ('non_ord', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('encoder', OneHotEncoder())]), non_ord_features.columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create nn pipeline\n",
    "pipeline = Pipeline(steps=[('classifier', MLPClassifier(hidden_layer_sizes=(32,32,32), early_stopping=True))])\n",
    "\n",
    "# pipeline with feature selection\n",
    "pipeline_C = Pipeline(steps=[\n",
    "    ('vthresh', VarianceThreshold()),\n",
    "    ('selector', SelectKBest(score_func=mutual_info_classif, k=40)),\n",
    "    ('classifier', MLPClassifier(hidden_layer_sizes=(32,32,32), early_stopping=True))\n",
    "])\n",
    "\n",
    "\n",
    "# preprocess and split data\n",
    "x = df_train.drop(columns=['classification target'])\n",
    "# encode the classification target\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df_train['classification target'])\n",
    "\n",
    "x_A = preprocessor_A.fit_transform(x)\n",
    "x_B = preprocessor_B.fit_transform(x)\n",
    "x_C = preprocessor_C.fit_transform(x)\n",
    "\n",
    "# Split train and test data\n",
    "trainX_A, testX_A, trainY_A, testY_A = train_test_split(x_A, y, test_size=0.2, random_state=4211)\n",
    "trainX_B, testX_B, trainY_B, testY_B = train_test_split(x_B, y, test_size=0.2, random_state=4211)\n",
    "trainX_C, testX_C, trainY_C, testY_C = train_test_split(x_C, y, test_size=0.2, random_state=4211)\n",
    "\n",
    "# run pipeline A\n",
    "start = time.time()\n",
    "pipeline.fit(trainX_A, trainY_A)\n",
    "end = time.time()\n",
    "elapsed_time = end - start\n",
    "# get f1 score\n",
    "prediction = pipeline.predict(testX_A)\n",
    "f1 = f1_score(testY_A, prediction)\n",
    "# get accuracy \n",
    "acc = accuracy_score(testY_A, prediction)\n",
    "print(\"F1 score for pipeline A: \" + str(f1))\n",
    "print(\"Accuracy for pipeline A: \" + str(acc))\n",
    "\n",
    "# run pipeline B\n",
    "start = time.time()\n",
    "pipeline.fit(trainX_B, trainY_B)\n",
    "end = time.time()\n",
    "elapsed_time = end - start\n",
    "# get f1 score\n",
    "prediction = pipeline.predict(testX_B)\n",
    "f1 = f1_score(testY_B, prediction)\n",
    "# get accuracy\n",
    "acc = accuracy_score(testY_B, prediction)\n",
    "print(\"F1 score for pipeline B: \" + str(f1))\n",
    "print(\"Accuracy for pipeline B: \" + str(acc))\n",
    "\n",
    "# pipeline C\n",
    "start = time.time()\n",
    "pipeline_C.fit(trainX_C, trainY_C)\n",
    "end = time.time()\n",
    "elapsed_time = end - start\n",
    "# get f1 score\n",
    "prediction = pipeline_C.predict(testX_C)\n",
    "f1 = f1_score(testY_C, prediction)\n",
    "# get accuracy\n",
    "acc = accuracy_score(testY_C, prediction)\n",
    "print(\"F1 score for pipeline C: \" + str(f1))\n",
    "print(\"Accuracy for pipeline C: \" + str(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m mlp \u001b[38;5;241m=\u001b[39m MLPClassifier(hidden_layer_sizes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m), early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(mlp, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# get best params\u001b[39;00m\n\u001b[1;32m     20\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:890\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 890\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:752\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    736\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \n\u001b[1;32m    738\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03m        Returns a trained MLP model.\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:489\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# Run the LBFGS solver\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_lbfgs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintercept_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_units\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# validate parameter weights\u001b[39;00m\n\u001b[1;32m    494\u001b[0m weights \u001b[38;5;241m=\u001b[39m chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoefs_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercepts_)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:533\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit_lbfgs\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    531\u001b[0m     iprint \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 533\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss_grad_lbfgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_coef_inter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxfun\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_fun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintercept_grads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter)\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_ \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:369\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    363\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:296\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:78\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:72\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 72\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:282\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._loss_grad_lbfgs\u001b[0;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the MLP loss function and its corresponding derivatives\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03mwith respect to the different parameters given in the initialization.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03mgrad : array-like, shape (number of nodes of all layers,)\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unpack(packed_coef_inter)\n\u001b[0;32m--> 282\u001b[0m loss, coef_grads, intercept_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backprop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintercept_grads\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m grad \u001b[38;5;241m=\u001b[39m _pack(coef_grads, intercept_grads)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, grad\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:327\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._backprop\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    324\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# Forward propagate\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Get loss\u001b[39;00m\n\u001b[1;32m    330\u001b[0m loss_func_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:174\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass\u001b[0;34m(self, activations)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Iterate over the hidden layers\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers_ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 174\u001b[0m     activations[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoefs_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     activations[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercepts_[i]\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# For the hidden layers\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/extmath.py:192\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 192\u001b[0m     \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m ):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_base.py:1483\u001b[0m, in \u001b[0;36missparse\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m sparray\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m _spbase\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n\u001b[0;32m-> 1483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21missparse\u001b[39m(x):\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001b[39;00m\n\u001b[1;32m   1485\u001b[0m \n\u001b[1;32m   1486\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# make the train and test data\n",
    "x = df_selected.drop(columns=['classification target', 'regression target'])\n",
    "y = df_selected['classification target']\n",
    "trainX, testX, trainY, testY = train_test_split(x, y, test_size=0.2, random_state=4211)\n",
    "\n",
    "# Define the hyperparameters that you want to tune\n",
    "param_grid = {\n",
    "    'activation': ['relu', 'identity', 'logistic', 'tanh'],\n",
    "    'solver': ['adam', 'lbfgs', 'sgd'],\n",
    "    'learning_rate': ['invscaling', 'adaptive', 'constant'],\n",
    "    'alpha': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(32,32,32), early_stopping=True)\n",
    "\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=10)\n",
    "grid_search.fit(trainX, trainY)\n",
    "\n",
    "# get best params\n",
    "best_params = grid_search.best_params\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# try params on data\n",
    "better_mlp = MLPClassifier(hidden_layer_sizes=(32, 32, 32), activation=best_params['activation'], solver=best_params['solver'], learning_rate=best_params['learning_rate'], alpha=best_params['alpha'])\n",
    "better_mlp.fit(trainX, trainY)\n",
    "accuracy = better_mlp.score(testX, testY)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
