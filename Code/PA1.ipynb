{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasha\\AppData\\Local\\Temp\\ipykernel_24224\\1367088338.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Import libraries, features and settings (not all of these are needed so pull what you need)\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import io\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn import preprocessing\n",
    "plt.rc(\"font\", size = 14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csvs as dataframes\n",
    "\n",
    "df_train = pd.read_csv('../Data/train.csv')\n",
    "df_test = pd.read_csv('../Data/test.csv')\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of instances and features\n",
    "\n",
    "num_instances, num_features = df_train.shape\n",
    "print(f\"Instances: {num_instances}\")\n",
    "print(f\"Features: {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = df_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = df_train.select_dtypes(include=['object']).columns\n",
    "print(\"Numerical features:\")\n",
    "print(num_features)\n",
    "print(\"Categorical features:\")\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find features with missing values and the proportion of missing values\n",
    "\n",
    "missing_values = df_train.isna().sum()\n",
    "missing_prop = missing_values / len(df_train)\n",
    "missing_data = pd.concat([missing_values, missing_prop], axis=1, keys=['Missing Values', 'Proportion'])\n",
    "print(missing_data[missing_data['Missing Values'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = df_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "for feature in num_features:\n",
    "    num_unique = df_train[feature].nunique()\n",
    "    if num_unique < 10:\n",
    "        print(f\"{feature} is a discrete feature with {num_unique} unique values\")\n",
    "    else:\n",
    "        print(f\"{feature} is a continuous feature with {num_unique} unique values\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
